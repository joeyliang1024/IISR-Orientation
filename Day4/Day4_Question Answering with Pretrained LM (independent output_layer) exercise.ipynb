{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lvg1JDRxGXmk"
   },
   "source": [
    "Search **TODO** to find out what needs to be done."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GCFV9SwGKO-1"
   },
   "source": [
    "# 環境準備 Prepare enviroment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /home/joeyliang/anaconda3/envs/nlp/lib/python3.10/site-packages (2.14.3)\n",
      "Requirement already satisfied: transformers in /home/joeyliang/anaconda3/envs/nlp/lib/python3.10/site-packages (4.31.0)\n",
      "Requirement already satisfied: accelerate in /home/joeyliang/anaconda3/envs/nlp/lib/python3.10/site-packages (0.21.0)\n",
      "Requirement already satisfied: evaluate in /home/joeyliang/anaconda3/envs/nlp/lib/python3.10/site-packages (0.4.0)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /home/joeyliang/anaconda3/envs/nlp/lib/python3.10/site-packages (from datasets) (10.0.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in /home/joeyliang/anaconda3/envs/nlp/lib/python3.10/site-packages (from datasets) (2.28.1)\n",
      "Requirement already satisfied: packaging in /home/joeyliang/anaconda3/envs/nlp/lib/python3.10/site-packages (from datasets) (21.3)\n",
      "Requirement already satisfied: aiohttp in /home/joeyliang/anaconda3/envs/nlp/lib/python3.10/site-packages (from datasets) (3.8.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /home/joeyliang/anaconda3/envs/nlp/lib/python3.10/site-packages (from datasets) (0.16.4)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /home/joeyliang/anaconda3/envs/nlp/lib/python3.10/site-packages (from datasets) (4.64.1)\n",
      "Requirement already satisfied: xxhash in /home/joeyliang/anaconda3/envs/nlp/lib/python3.10/site-packages (from datasets) (3.1.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/joeyliang/anaconda3/envs/nlp/lib/python3.10/site-packages (from datasets) (1.23.3)\n",
      "Requirement already satisfied: multiprocess in /home/joeyliang/anaconda3/envs/nlp/lib/python3.10/site-packages (from datasets) (0.70.13)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/joeyliang/anaconda3/envs/nlp/lib/python3.10/site-packages/PyYAML-6.0-py3.10-linux-x86_64.egg (from datasets) (6.0)\n",
      "Requirement already satisfied: pandas in /home/joeyliang/anaconda3/envs/nlp/lib/python3.10/site-packages (from datasets) (1.4.4)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in /home/joeyliang/anaconda3/envs/nlp/lib/python3.10/site-packages (from datasets) (2022.10.0)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /home/joeyliang/anaconda3/envs/nlp/lib/python3.10/site-packages (from datasets) (0.3.5.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/joeyliang/anaconda3/envs/nlp/lib/python3.10/site-packages (from transformers) (2022.10.31)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /home/joeyliang/anaconda3/envs/nlp/lib/python3.10/site-packages (from transformers) (0.3.1)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /home/joeyliang/anaconda3/envs/nlp/lib/python3.10/site-packages (from transformers) (0.13.1)\n",
      "Requirement already satisfied: filelock in /home/joeyliang/anaconda3/envs/nlp/lib/python3.10/site-packages (from transformers) (3.8.0)\n",
      "Requirement already satisfied: psutil in /home/joeyliang/anaconda3/envs/nlp/lib/python3.10/site-packages (from accelerate) (5.9.0)\n",
      "Requirement already satisfied: torch>=1.10.0 in /home/joeyliang/anaconda3/envs/nlp/lib/python3.10/site-packages (from accelerate) (2.0.1)\n",
      "Requirement already satisfied: responses<0.19 in /home/joeyliang/anaconda3/envs/nlp/lib/python3.10/site-packages (from evaluate) (0.18.0)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /home/joeyliang/anaconda3/envs/nlp/lib/python3.10/site-packages (from aiohttp->datasets) (2.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/joeyliang/anaconda3/envs/nlp/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/joeyliang/anaconda3/envs/nlp/lib/python3.10/site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/joeyliang/anaconda3/envs/nlp/lib/python3.10/site-packages (from aiohttp->datasets) (21.4.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/joeyliang/anaconda3/envs/nlp/lib/python3.10/site-packages (from aiohttp->datasets) (1.8.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/joeyliang/anaconda3/envs/nlp/lib/python3.10/site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/joeyliang/anaconda3/envs/nlp/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/joeyliang/anaconda3/envs/nlp/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (4.3.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/joeyliang/anaconda3/envs/nlp/lib/python3.10/site-packages (from packaging->datasets) (3.0.9)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/joeyliang/anaconda3/envs/nlp/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (1.26.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/joeyliang/anaconda3/envs/nlp/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/joeyliang/anaconda3/envs/nlp/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2022.9.24)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /home/joeyliang/anaconda3/envs/nlp/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (2.14.3)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /home/joeyliang/anaconda3/envs/nlp/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (11.7.4.91)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /home/joeyliang/anaconda3/envs/nlp/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /home/joeyliang/anaconda3/envs/nlp/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (11.7.99)\n",
      "Requirement already satisfied: triton==2.0.0 in /home/joeyliang/anaconda3/envs/nlp/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (2.0.0)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /home/joeyliang/anaconda3/envs/nlp/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (11.7.91)\n",
      "Requirement already satisfied: sympy in /home/joeyliang/anaconda3/envs/nlp/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.12)\n",
      "Requirement already satisfied: jinja2 in /home/joeyliang/anaconda3/envs/nlp/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.0.3)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /home/joeyliang/anaconda3/envs/nlp/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (11.4.0.1)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /home/joeyliang/anaconda3/envs/nlp/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /home/joeyliang/anaconda3/envs/nlp/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /home/joeyliang/anaconda3/envs/nlp/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (11.7.101)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /home/joeyliang/anaconda3/envs/nlp/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (10.2.10.91)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /home/joeyliang/anaconda3/envs/nlp/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (10.9.0.58)\n",
      "Requirement already satisfied: networkx in /home/joeyliang/anaconda3/envs/nlp/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1)\n",
      "Requirement already satisfied: setuptools in /home/joeyliang/anaconda3/envs/nlp/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.10.0->accelerate) (65.6.3)\n",
      "Requirement already satisfied: wheel in /home/joeyliang/anaconda3/envs/nlp/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.10.0->accelerate) (0.38.4)\n",
      "Requirement already satisfied: cmake in /home/joeyliang/anaconda3/envs/nlp/lib/python3.10/site-packages (from triton==2.0.0->torch>=1.10.0->accelerate) (3.27.0)\n",
      "Requirement already satisfied: lit in /home/joeyliang/anaconda3/envs/nlp/lib/python3.10/site-packages (from triton==2.0.0->torch>=1.10.0->accelerate) (16.0.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/joeyliang/anaconda3/envs/nlp/lib/python3.10/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/joeyliang/anaconda3/envs/nlp/lib/python3.10/site-packages (from pandas->datasets) (2022.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/joeyliang/anaconda3/envs/nlp/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/joeyliang/anaconda3/envs/nlp/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/joeyliang/anaconda3/envs/nlp/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade datasets transformers accelerate evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 538,
     "status": "ok",
     "timestamp": 1691362289899,
     "user": {
      "displayName": "薛竣祐",
      "userId": "03276991785061169168"
     },
     "user_tz": -480
    },
    "id": "fW3wVR5u6deC",
    "outputId": "d623bfd0-3eed-47e9-b2ab-d146b9bd5a5a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Aug  8 15:48:51 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 470.103.01   Driver Version: 470.103.01   CUDA Version: 11.4     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  Off  | 00000000:01:00.0 Off |                  N/A |\n",
      "| 35%   54C    P0    60W / 198W |      2MiB /  8119MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA GeForce ...  Off  | 00000000:17:00.0 Off |                  N/A |\n",
      "|  0%   39C    P8     7W / 198W |      2MiB /  8119MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  NVIDIA GeForce ...  Off  | 00000000:65:00.0 Off |                  N/A |\n",
      "|  0%   41C    P8     8W / 198W |     19MiB /  8117MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    2   N/A  N/A      1489      G   /usr/lib/xorg/Xorg                 16MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-08 15:48:53.933980: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-08-08 15:48:54.578129: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:\n",
      "2023-08-08 15:48:54.578203: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:\n",
      "2023-08-08 15:48:54.578213: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "# 檢查GPU，Colab會自動分配GPU，Tesla T4以上比較好，不然建議終止工作階段重連來隨機更換GPU（重啟不會更換GPU）\n",
    "# Check GPU, Colab will auto-allocate GPU, it is better to use Tesla T4 or a more powerful GPU, otherwise you should kill the runtime to switch GPU randomly\n",
    "!nvidia-smi\n",
    "import torch\n",
    "from transformers import default_data_collator\n",
    "from transformers import get_scheduler\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "import math\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1124,
     "status": "ok",
     "timestamp": 1691362306491,
     "user": {
      "displayName": "薛竣祐",
      "userId": "03276991785061169168"
     },
     "user_tz": -480
    },
    "id": "VVZWdSNnILT7",
    "outputId": "859f9d12-fb99-4967-d3d0-7ac74c38b92a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.31.0\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "\n",
    "print(transformers.__version__) # version check, 4.31.0 verified"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rEJBSTyZIrIb"
   },
   "source": [
    "# 微調預訓練模型 Fine-tune a Pre-trained Language Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A76hdsEEILT9"
   },
   "source": [
    "我們將會微調BERT等預訓練模型來進行QA任務，要注意的是，這個範例中的回答方式不是透過文本生成來回答問題，而是擷取給定段落中的文本片段來進行回答。目前，最常用的QA資料集為[SQuAD](https://rajpurkar.github.io/SQuAD-explorer/)，以下為SQuAD的範例：\n",
    "\n",
    "We will fine-tune pre-trained models such as BERT for QA tasks. Note that in this example, instead of answering the question through text generation, the responses are extracted from text snippets in the given passage. Currently, the most commonly used QA dataset is [SQuAD](https://rajpurkar.github.io/SQuAD-explorer/), and the following is an example of SQuAD:\n",
    "\n",
    "<img src=\"https://i.imgur.com/sOKTl1Z.jpg\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O7mFn6vyd6Pu"
   },
   "source": [
    "## 超參數設定 Hyperparameters setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "y78CVd6rLxqM"
   },
   "outputs": [],
   "source": [
    "class arguments:\n",
    "  def __init__(self,batch_size,model_checkpoint):\n",
    "    self.preprocessing_num_workers=4\n",
    "    self.max_seq_length=512\n",
    "    self.pad_to_max_length=True\n",
    "    self.model_name_or_path=model_checkpoint\n",
    "    self.per_device_train_batch_size=batch_size\n",
    "    self.per_device_eval_batch_size=batch_size\n",
    "    self.learning_rate=3e-5\n",
    "    self.weight_decay=0.01\n",
    "    self.num_train_epochs=1\n",
    "    self.max_train_steps=None\n",
    "    self.gradient_accumulation_steps=1 # 設定需累積幾個batch的梯度再更新權重，可變相節省記憶體，1為不累積 Set to accumulate the gradient of several batch before updating the weights to save memory, 1 is not accumulate.\n",
    "    self.lr_scheduler_type=\"linear\"\n",
    "    self.num_warmup_steps=0\n",
    "    self.output_dir=\"output\" # 如果不想存model和結果可以設置成None，大約佔400MB Set to None if you don't want to save the model and result, it takes about 400MB\n",
    "    self.doc_stride=128 # 重疊的token長度 The overlapping token length\n",
    "    self.n_best_size=20 # 選擇多少「答案」作為候選 How many \"answers\" to choose as candidates\n",
    "    self.squad_v2 = False # 設定使用SQUAD版本 Switch between SQUAD v1 or v2\n",
    "    self.null_score_diff_threshold=0.0 # 結果可能為無答案時選擇no answer的門檻 The threshold of choosing \"no answer\" when there is no answer.\n",
    "    self.version_2_with_negative = False\n",
    "    self.max_answer_length=30\n",
    "    self.max_train_samples=4000 # 限制訓練資料大小來節省時間，正式訓練時請改回\"None\" Limit training data size to save time. Change to \"None\" when in actual training\n",
    "    self.max_eval_samples=500 # 同上 As above\n",
    "    self.overwrite_cache=True\n",
    "\n",
    "\n",
    "# Download Model from HuggingFace Library. Supported model: BERT、ELECTRA、RoBERTa、DeBERTa. Others need to be confirmed. ref:https://huggingface.co/models\n",
    "model_checkpoint = \"bert-base-cased\"\n",
    "batch_size = 8 # Suggest gradient_accumulation_steps * batch_size >= 16\n",
    "args = arguments(batch_size, model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "YOLYvWG_GOi9"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# make sure output_dir exist\n",
    "if args.output_dir is not None and not os.path.exists(args.output_dir):\n",
    "  os.makedirs(args.output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "whPRbBNbIrIl"
   },
   "source": [
    "## 下載資料集 Download dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W7QYTpxXIrIl"
   },
   "source": [
    "這部分將使用[Datasets](https://github.com/huggingface/datasets) 提供的 `load_dataset` 來完成資料集準備。當然，直接從其他QA資料集的官方網站下載也可以。如果要用自己的json、csv格式的dataset，load_dataset也可以完成。請看官方文檔[Datasets documentation](https://huggingface.co/docs/datasets/loading_datasets.html#from-local-files)。\n",
    "\n",
    "This part will use `load_dataset` provided by [Datasets](https://github.com/huggingface/datasets) to complete the dataset preparation. Of course, it is possible to download it directly from the official website of other QA datasets. If you want to use your own dataset in json, csv format, load_dataset can also be done. Please see the official documentation [Datasets documentation](https://huggingface.co/docs/datasets/loading_datasets.html#from-local-files).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "IreSlFmlIrIm"
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "datasets = load_dataset(\"squad_v2\" if args.squad_v2 else \"squad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1691362308652,
     "user": {
      "displayName": "薛竣祐",
      "userId": "03276991785061169168"
     },
     "user_tz": -480
    },
    "id": "GWiVUF0jIrIv",
    "outputId": "7fdfb4bc-5100-4564-a48a-2b1e635273e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets structure:\n",
      "\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
      "        num_rows: 87599\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
      "        num_rows: 10570\n",
      "    })\n",
      "})\n",
      "\n",
      "\n",
      "train data：\n",
      "\n",
      "{   'answers': {'answer_start': [515], 'text': ['Saint Bernadette Soubirous']},\n",
      "    'context': 'Architecturally, the school has a Catholic character. Atop the '\n",
      "               \"Main Building's gold dome is a golden statue of the Virgin \"\n",
      "               'Mary. Immediately in front of the Main Building and facing it, '\n",
      "               'is a copper statue of Christ with arms upraised with the '\n",
      "               'legend \"Venite Ad Me Omnes\". Next to the Main Building is the '\n",
      "               'Basilica of the Sacred Heart. Immediately behind the basilica '\n",
      "               'is the Grotto, a Marian place of prayer and reflection. It is '\n",
      "               'a replica of the grotto at Lourdes, France where the Virgin '\n",
      "               'Mary reputedly appeared to Saint Bernadette Soubirous in 1858. '\n",
      "               'At the end of the main drive (and in a direct line that '\n",
      "               'connects through 3 statues and the Gold Dome), is a simple, '\n",
      "               'modern stone statue of Mary.',\n",
      "    'id': '5733be284776f41900661182',\n",
      "    'question': 'To whom did the Virgin Mary allegedly appear in 1858 in '\n",
      "                'Lourdes France?',\n",
      "    'title': 'University_of_Notre_Dame'}\n",
      "\n",
      "\n",
      "validation data：\n",
      "\n",
      "{   'answers': {   'answer_start': [177, 177, 177],\n",
      "                   'text': [   'Denver Broncos',\n",
      "                               'Denver Broncos',\n",
      "                               'Denver Broncos']},\n",
      "    'context': 'Super Bowl 50 was an American football game to determine the '\n",
      "               'champion of the National Football League (NFL) for the 2015 '\n",
      "               'season. The American Football Conference (AFC) champion Denver '\n",
      "               'Broncos defeated the National Football Conference (NFC) '\n",
      "               'champion Carolina Panthers 24–10 to earn their third Super '\n",
      "               \"Bowl title. The game was played on February 7, 2016, at Levi's \"\n",
      "               'Stadium in the San Francisco Bay Area at Santa Clara, '\n",
      "               'California. As this was the 50th Super Bowl, the league '\n",
      "               'emphasized the \"golden anniversary\" with various gold-themed '\n",
      "               'initiatives, as well as temporarily suspending the tradition '\n",
      "               'of naming each Super Bowl game with Roman numerals (under '\n",
      "               'which the game would have been known as \"Super Bowl L\"), so '\n",
      "               'that the logo could prominently feature the Arabic numerals '\n",
      "               '50.',\n",
      "    'id': '56be4db0acb8001400a502ec',\n",
      "    'question': 'Which NFL team represented the AFC at Super Bowl 50?',\n",
      "    'title': 'Super_Bowl_50'}\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "\n",
    "print(\"datasets structure:\\n\")\n",
    "pp.pprint(datasets)\n",
    "print(\"\\n\\ntrain data：\\n\")\n",
    "pp.pprint(datasets['train'][0])\n",
    "print(\"\\n\\nvalidation data：\\n\")\n",
    "pp.pprint(datasets['validation'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n9qywopnIrJH"
   },
   "source": [
    "## 資料前處理 Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WNcbMrQCUjCF"
   },
   "source": [
    "將文本轉為embedding，通常Transformers提供的 Tokenizer 可以自動將文本Tokenize並轉換為model可以讀取的形式。BERT的輸入格式參考下方圖片：  \n",
    "\n",
    "To convert text to embedding, usually the Tokenizer provided by Transformers can automatically tokenize the text and convert it into a form that can be read by the model, refer to the image below for the input format of BERT:\n",
    "\n",
    "<img src=\"https://i.imgur.com/xQIkHWu.png\" width=\"800\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "eXNLu_-nIrJI"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(args.model_name_or_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 324,
     "status": "ok",
     "timestamp": 1691362308961,
     "user": {
      "displayName": "薛竣祐",
      "userId": "03276991785061169168"
     },
     "user_tz": -480
    },
    "id": "3oUhQFYS79Vm",
    "outputId": "103c220a-39e2-4aa8-c6e7-69201396f106"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{   'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "    'input_ids': [   101,\n",
      "                     2627,\n",
      "                     1567,\n",
      "                     1563,\n",
      "                     16396,\n",
      "                     136,\n",
      "                     102,\n",
      "                     1563,\n",
      "                     16396,\n",
      "                     1110,\n",
      "                     1363,\n",
      "                     119,\n",
      "                     6064,\n",
      "                     7871,\n",
      "                     1122,\n",
      "                     119,\n",
      "                     102],\n",
      "    'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
      "['[CLS]', 'Who', 'love', 'II', '##SR', '?', '[SEP]', 'II', '##SR', 'is', 'good', '.', 'Everyone', 'loves', 'it', '.', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "# 檢視tokenizer輸出 Quick view about tokenizer output\n",
    "query = \"Who love IISR?\"\n",
    "context = \"IISR is good. Everyone loves it.\"\n",
    "token = tokenizer(query, context)\n",
    "pp.pprint(token)\n",
    "print(tokenizer.convert_ids_to_tokens(token[\"input_ids\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 278,
     "referenced_widgets": [
      "a6194a2f36ad4a1a80ef5f778b56a702",
      "e360148e58fe4523a6a724a511990584",
      "b4062756718a4e599936154d925495aa",
      "a75a170085f046a39ac98219c87881f4",
      "f4a1e21bf914467297357514111a0a07",
      "5736c6520c704016a8f00cac6caba60f",
      "a9be2beb2e9a4dab887aae4c7141aa19",
      "6032afe69bea41bf939165f0a92b5373",
      "869083dbde4d4313b6ef27825a5e8dba",
      "d5f51cabee4b41a9920aaa89eb101cca",
      "1a02b8505e384ebe9b3d1e82ca546b0f",
      "807f36c8143b4012adb402613e32185d",
      "5b2c553e26054ed5818582f315a4e0fc",
      "e7d065453af54786b8d3716fb33de912",
      "909602f7e6ac46da906df869cf12d1b5",
      "c85b6855bd094b64982028e269bc0f2c",
      "09da23cc8e9349688a79d2c29a05a6c7",
      "8e316628178e4504a981dd725bd7274a",
      "c666f8601b6c4f3fba3d327c3ee8173b",
      "b41fb4576f854da5bd0fc3adb4274e46",
      "8266258b51234fe480e6259c318ec284",
      "9cbfd243e4c94a7e9b3fa8441e0804b1"
     ]
    },
    "executionInfo": {
     "elapsed": 8203,
     "status": "ok",
     "timestamp": 1691362317156,
     "user": {
      "displayName": "薛竣祐",
      "userId": "03276991785061169168"
     },
     "user_tz": -480
    },
    "id": "n4-PAZnYbiya",
    "outputId": "b77a5ef5-0934-4056-c546-e4207aabe555"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e40901b17bb4631a8e0de2e81306bd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on train dataset (num_proc=4):   0%|          | 0/4000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69b7d8f38c47464d9cab12fa2d981aca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on validation dataset (num_proc=4):   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataset:\n",
      "Dataset({\n",
      "    features: ['input_ids', 'token_type_ids', 'attention_mask', 'start_positions', 'end_positions'],\n",
      "    num_rows: 4000\n",
      "})\n",
      "\n",
      "\n",
      "eval_dataset:\n",
      "Dataset({\n",
      "    features: ['input_ids', 'token_type_ids', 'attention_mask', 'offset_mapping', 'example_id'],\n",
      "    num_rows: 500\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# 主要處理的問題是部分passage可能超過設定的max_seq_length，因此需要對文章分段，並調整答案的index\n",
    "# The main problem is some passage length may be longer than max_seq_length. So it needs segmentation and re-indexing\n",
    "# 注意，為了簡化流程在這我們只切分兩資料集，一份訓練一份評估\n",
    "# Note that in order to simplify the process here we only cut it into two datasets, one for training and one for evaluation\n",
    "\n",
    "from dataset_preprocess import QAdataset\n",
    "SQuAD_dataset = QAdataset(datasets, tokenizer, args)\n",
    "\n",
    "train_dataset = SQuAD_dataset.generate_train_dataset()\n",
    "eval_dataset = SQuAD_dataset.generate_eval_dataset()\n",
    "\n",
    "print(\"train_dataset:\")\n",
    "pp.pprint(train_dataset)\n",
    "\n",
    "print(\"\\n\\neval_dataset:\")\n",
    "pp.pprint(eval_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-SKuV_7MJD5Y"
   },
   "source": [
    "## 建構模型輸出層 Construct output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "eBJtf6XnGd9m"
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "class QuestionAnsweringModelOutput: # The format of output\n",
    "    def __init__(self, loss, start_logits, end_logits):\n",
    "      self.loss = loss\n",
    "      self.start_logits = start_logits\n",
    "      self.end_logits = end_logits\n",
    "\n",
    "class OutputQA(nn.Module): # Only output layer\n",
    "\n",
    "    def __init__(self,hidden_dim):\n",
    "        super(OutputQA, self).__init__()\n",
    "        self.num_labels = 2\n",
    "        self.qa_outputs_lin = nn.Linear(hidden_dim, 2)# TODO # 提示，使用linear即可 (Use linear layer)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        hidden_state,\n",
    "        start_positions=None,\n",
    "        end_positions=None\n",
    "    ):\n",
    "\n",
    "        logits = self.qa_outputs_lin(hidden_state)# TODO\n",
    "\n",
    "        start_logits, end_logits = torch.split(logits, 1, 2)# TODO # 提示，需要使用到torch.split()方法 (This need torch.split() func)\n",
    "\n",
    "        start_logits = start_logits.squeeze(-1).contiguous()\n",
    "        end_logits = end_logits.squeeze(-1).contiguous()\n",
    "\n",
    "\n",
    "\n",
    "        total_loss = None\n",
    "        if start_positions is not None and end_positions is not None:\n",
    "            # If we are on multi-GPU, split add a dimension\n",
    "            if len(start_positions.size()) > 1:\n",
    "                start_positions = start_positions.squeeze(-1)\n",
    "            if len(end_positions.size()) > 1:\n",
    "                end_positions = end_positions.squeeze(-1)\n",
    "\n",
    "            # 若start/end 位置超出inputs範圍，需要調整在範圍之內\n",
    "            # Adjust the start/end position, if they out of the range of inputs\n",
    "            max_index = start_logits.size(1)\n",
    "            start_positions = torch.clamp(start_positions, min=0, max=max_index)# TODO # 提示，使用torch.clamp()調整數值範圍 (Use torch.clamp() to adjust the range of values)\n",
    "            end_positions =   torch.clamp(end_positions, min=0, max=max_index)# TODO # 提示，使用torch.clamp()調整數值範圍 (Use torch.clamp() to adjust the range of values)\n",
    "\n",
    "            # loss 計算，提示：建議使用CrossEntropyLoss\n",
    "            # Calculate the loss, Suggest use CrossEntropyLoss\n",
    "\n",
    "            loss_fct = CrossEntropyLoss() # TODO\n",
    "            start_loss = loss_fct(start_logits, start_positions)# TODO\n",
    "            end_loss =   loss_fct(end_logits, end_positions)# TODO\n",
    "            total_loss = start_loss + end_loss # TODO # 簡單相加即可 Simply add up\n",
    "\n",
    "\n",
    "        return QuestionAnsweringModelOutput(\n",
    "            loss=total_loss,\n",
    "            start_logits=start_logits,\n",
    "            end_logits=end_logits\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "545PP3o8IrJV"
   },
   "source": [
    "## 微調模型 Fine-tune model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FBiW8UpKIrJW"
   },
   "source": [
    "可以使用Transformers預設好的`AutoModelForQuestionAnswering`進行預訓練，但在這邊我們自己定義。  \n",
    "Pre-training can be done using Transformers' preset `AutoModelForQuestionAnswering`, but we define it ourselves here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "1i2KLGVgt8HY"
   },
   "outputs": [],
   "source": [
    "# Load pre-train model\n",
    "from transformers import RobertaModel, ElectraModel, DebertaModel, BertModel, AutoModel\n",
    "\n",
    "def select_model(model_name):\n",
    "  model_types = {\n",
    "    \"roberta\": RobertaModel,\n",
    "    \"electra\": ElectraModel,\n",
    "    \"deberta\": DebertaModel,\n",
    "    \"bert\": BertModel\n",
    "  }\n",
    "  for model_type in model_types.keys():\n",
    "    if model_type in model_name:\n",
    "      return model_types[model_type].from_pretrained(model_name)\n",
    "  print(\"warning: Using AutoModel but not sure about the type of model_name_or_path.\")\n",
    "  return AutoModel.from_pretrained(args.model_name_or_path)\n",
    "\n",
    "model = select_model(args.model_name_or_path)\n",
    "output_layer = OutputQA(model.config.hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "KsB5WHvBtHth"
   },
   "outputs": [],
   "source": [
    "# Dataloader\n",
    "\n",
    "# default_data_collator會將數筆資料堆疊在一起形成batch\n",
    "# default_data_collator will stack rows of data together to become a batch\n",
    "data_collator = default_data_collator\n",
    "\n",
    "# 通常會將訓練資料打亂以提升通用性，避免過擬合\n",
    "# Often the training data will be shuffled to enhance generalizability and to avoid overfitting\n",
    "train_dataloader = DataLoader(train_dataset, shuffle=True, collate_fn=data_collator, batch_size=args.per_device_train_batch_size)\n",
    "\n",
    "# 通常會將驗證資料不打亂避免造成分數計算的不一致\n",
    "# Often the validation data is not shuffled to avoid inconsistencies in the score calculation\n",
    "eval_dataset_for_model = eval_dataset.remove_columns([\"example_id\", \"offset_mapping\"])\n",
    "eval_dataloader = DataLoader(eval_dataset_for_model, shuffle=False, collate_fn=data_collator, batch_size=args.per_device_eval_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "IfIhinqJv1DD"
   },
   "outputs": [],
   "source": [
    "# Optimizer\n",
    "# 輸出層的學習率通常要設置大於原Bert的學習率。\n",
    "# 另外Bert權重分兩組，一個有weight decay，另一組不設。\n",
    "# Weight decay是在loss中加入懲罰，用來避免過擬合。\n",
    "# The learning rate of the output layer is usually set larger than the original Bert's learning rate.\n",
    "# In addition, the Bert weights are divided into two groups, one with weight decay and the other without.\n",
    "# The weight decay is a penalty added to the loss to avoid overfitting.\n",
    "no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
    "optimizer_grouped_parameters = [\n",
    "    {\n",
    "        \"params\": [p for n, p in output_layer.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "        \"weight_decay\": args.weight_decay,\n",
    "        \"lr\": args.learning_rate*10, # 10 times larger\n",
    "    },\n",
    "    {\n",
    "        \"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "        \"weight_decay\": args.weight_decay,\n",
    "    },\n",
    "    {\n",
    "        \"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)],\n",
    "        \"weight_decay\": 0.0,\n",
    "    }\n",
    "]\n",
    "optimizer = AdamW(optimizer_grouped_parameters, lr=args.learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5841,
     "status": "ok",
     "timestamp": 1691362336229,
     "user": {
      "displayName": "薛竣祐",
      "userId": "03276991785061169168"
     },
     "user_tz": -480
    },
    "id": "NXod3ZCev--d",
    "outputId": "afe82ce9-8d69-46d6-8970-92355828a76b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distributed environment: NO\n",
      "Num processes: 1\n",
      "Process index: 0\n",
      "Local process index: 0\n",
      "Device: cuda\n",
      "\n",
      "Mixed precision type: no\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from accelerate import Accelerator\n",
    "# 用`accelerate`自動切換設備/多線程，跟寫.cuda()或.to(device)效果相同，可參考 https://pypi.org/project/accelerate/\n",
    "# Use `accelerate` to switch device/multi-threading automatically, same effect as writing .cuda() or .to(device), see https://pypi.org/project/accelerate/\n",
    "accelerator = Accelerator()\n",
    "print(accelerator.state)\n",
    "\n",
    "# 需注意倒傳遞時要用`accelerator.backward(loss)`取代`loss.backward()`\n",
    "# Be careful to replace `accelerator.backward(loss)` with `loss.backward()` when back propagation\n",
    "output_layer, model, optimizer, train_dataloader, eval_dataloader = accelerator.prepare(\n",
    "    output_layer, model, optimizer, train_dataloader, eval_dataloader\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "lzhZTJDxwN_N"
   },
   "outputs": [],
   "source": [
    "# 根據步數設定學習率調整策略，可以調整args.lr_scheduler_type為其他策略，例如cosine\n",
    "# Set the learning rate adjustment strategy based on the number of steps, you can adjust args.lr_scheduler_type to other strategies, such as cosine\n",
    "num_update_steps_per_epoch = math.ceil(len(train_dataloader) / args.gradient_accumulation_steps) # 計算總訓練步數 Total training step\n",
    "\n",
    "if args.max_train_steps is None:\n",
    "    args.max_train_steps = args.num_train_epochs * num_update_steps_per_epoch\n",
    "else:\n",
    "    args.num_train_epochs = math.ceil(args.max_train_steps / num_update_steps_per_epoch)\n",
    "\n",
    "lr_scheduler = get_scheduler(\n",
    "    name=args.lr_scheduler_type, # default: linear\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=args.num_warmup_steps, # warm up steps is usually 1/10 of the total steps, we default 0 here\n",
    "    num_training_steps=args.max_train_steps,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 164,
     "referenced_widgets": [
      "18b4801ced9b4e30a6d8f6c4e1de3e5e",
      "cbe73ae13fb849aca282e64ff908c23c",
      "e5220750031d4e089c9ae5430130f262",
      "5f75259418ab4964aa44345ac4c8d34e",
      "a2e51565db724c5682756c24814679a9",
      "dfb902be24b34fc5810aaaa92a7feec9",
      "ba1bd9516f2c48acaea8960d3cb3d860",
      "014bf9be72fd4f629ff2fcc88efa9c69",
      "49080f24cf454143b1b3d6b160a982bf",
      "9a7fc4d2ebdc47e0b3da10c232886182",
      "dbed778fc2ff4b749fa3b3e027d14088"
     ]
    },
    "executionInfo": {
     "elapsed": 395858,
     "status": "ok",
     "timestamp": 1691362732076,
     "user": {
      "displayName": "薛竣祐",
      "userId": "03276991785061169168"
     },
     "user_tz": -480
    },
    "id": "6n9bYhy9wU0I",
    "outputId": "d84d0bdf-f69e-44b3-d786-a2ac355c4552"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 4000\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 500\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfb6976a0c0e40ed882feda2f3f38828",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Start training\n",
    "total_batch_size = args.per_device_train_batch_size * accelerator.num_processes * args.gradient_accumulation_steps\n",
    "\n",
    "print(\"***** Running training *****\")\n",
    "print(f\"  Num examples = {len(train_dataset)}\")\n",
    "print(f\"  Num Epochs = {args.num_train_epochs}\")\n",
    "print(f\"  Instantaneous batch size per device = {args.per_device_train_batch_size}\")\n",
    "print(f\"  Total train batch size (w. parallel, distributed & accumulation) = {total_batch_size}\")\n",
    "print(f\"  Gradient Accumulation steps = {args.gradient_accumulation_steps}\")\n",
    "print(f\"  Total optimization steps = {args.max_train_steps}\")\n",
    "\n",
    "# Setup progress bar. The \"disable\" parameter is to limit only show one progress bar when using multiple GPUs, it doesn't matter in Colab\n",
    "# 進度條設定，disable部分是為了規定多個GPU時只顯示一個進度條，在Colab中有沒有都不影響\n",
    "progress_bar = tqdm(range(args.max_train_steps), disable=not accelerator.is_local_main_process)\n",
    "\n",
    "completed_steps = 0\n",
    "for epoch in range(args.num_train_epochs):\n",
    "    model.train()\n",
    "    output_layer.train()\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        # batch裡包含了訓練用的word index, mask, segment以及算loss用的label，只將需要的資料傳進model\n",
    "        # batch contains the word index, mask, segment for training and label for loss calculation, only the required data is passed into the model.\n",
    "        input = {key: value for key, value in batch.items() if key not in ['start_positions','end_positions']}\n",
    "        encoding = model(**input)\n",
    "        outputs = output_layer(encoding['last_hidden_state'], batch['start_positions'], batch['end_positions']) # TODO\n",
    "        loss = outputs.loss / args.gradient_accumulation_steps\n",
    "        accelerator.backward(loss)\n",
    "        if step % args.gradient_accumulation_steps == 0 or step == len(train_dataloader) - 1:\n",
    "            optimizer.step()\n",
    "            lr_scheduler.step()\n",
    "            optimizer.zero_grad()\n",
    "            progress_bar.update(1)\n",
    "            completed_steps += 1\n",
    "\n",
    "        if completed_steps >= args.max_train_steps:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jcpiQTRnN4um"
   },
   "source": [
    "# 評估模型 Evalation\n",
    "\n",
    "### 評估方法說明\n",
    "\n",
    "SQuAD使用Exact Match (EM)和F1 score計算分數。對每個「問題+答案」對計算並在最後平均而得。當一個問題可能有多個正確答案時，計算所有可能的正確答案的最大分數。\n",
    "\n",
    "1.   EM：對於每個「問題+答案」對，如果模型預測的詞句與（其中一個）真實答案的詞句完全匹配，EM=1，否則EM=0。嚴格的全有或全無指標；偏離一個詞句就會得到0分。\n",
    "2.   F1：透過計算預測和真實答案相同token數來得出分數：\n",
    "  *   Precision = 相同token數量與預測總token數的比例\n",
    "  *   Recall = 相同token數量與真實答案總token數的比例\n",
    "  *   F1 = 2 \\* (Precision \\* Recall) / (Precision + Recall)\n",
    "\n",
    "SQuAD uses Exact Match (EM) and F1 score to calculate scores. Each \"question + answer\" pair is calculated and averaged at the end. When a question may have more than one correct answer, the maximum score of all possible correct answers is calculated.\n",
    "\n",
    "1. EM: For each \"question-answer\" pair, EM = 1 if the model's predicted phrase exactly matches (one of) the true answer's phrase, otherwise EM = 0. Strictly an all-or-nothing metric; a deviation of one phrase results in a score of 0. 2.\n",
    "2. F1: Score is obtained by calculating the number of tokens that are the same in the prediction and ground truth:\n",
    "  * Precision = the ratio of the number of same tokens to total tokens in the prediction.\n",
    "  * Recall = the ratio of the number of same tokens to total tokens in the ground truth.\n",
    "  * F1 = 2 \\* (Precision \\* Recall) / (Precision + Recall)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1284,
     "status": "ok",
     "timestamp": 1691362733352,
     "user": {
      "displayName": "薛竣祐",
      "userId": "03276991785061169168"
     },
     "user_tz": -480
    },
    "id": "9t4V4YF8L0q4",
    "outputId": "5689d233-9c51-49fa-de89-fa2d8013ea21"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b82759f1beb4d07aca916012e9d0b51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/4.53k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85065508d20842c4a84e2dd4664efdce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading extra modules:   0%|          | 0.00/3.32k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "This metric wrap the official scoring script for version 1 of the Stanford Question Answering Dataset (SQuAD).\n",
      "\n",
      "Stanford Question Answering Dataset (SQuAD) is a reading comprehension dataset, consisting of questions posed by\n",
      "crowdworkers on a set of Wikipedia articles, where the answer to every question is a segment of text, or span,\n",
      "from the corresponding reading passage, or the question might be unanswerable.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import evaluate\n",
    "# 讀取預先設計好的評估方法 Load pre-defined metric\n",
    "metric = evaluate.load(\"squad_v2\" if args.squad_v2 else \"squad\")\n",
    "print(metric.description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 163,
     "referenced_widgets": [
      "527974f6accb4501bb460eb7b6117551",
      "5e893ab0c1d04738a7a7f44389a3e010",
      "91bd03865250418fae5d9863756912d1",
      "d3229be921d24abdbb0482bfa70bbce9",
      "892bb743e7c042cda9d3f159a0f761ae",
      "c0ee078fe02c4f19bc5991cf1ec4db68",
      "addf7de6d66f4b2f99dbbf06f06ac6f3",
      "2482fbfaafc14d699b38ea940f13e48e",
      "842c593f0c3648bd934bb95848dd48db",
      "9b1761ce967240b8b97d3af03b188a74",
      "2bc8fdf5bb21454bb99502539afa9d4c",
      "0cb440e7369a4702a9af9989bf441df9",
      "ad5232729b534cd0aa4e766247b20c40",
      "de0dfea5e6264cfaae7334b2ebcb0a8a",
      "b7739956628948a4a7dec5a7102fcaee",
      "ad118d3b74b449e9af2da40b08f126f7",
      "7b47484c555747bca3aaf45f3ac67266",
      "23095b6a962a4485b487cce7ae09af87",
      "6f0a34df396f44f7b6de5eb7b778815a",
      "a3103ec77d8b4a379e5cf5ca338dc6c5",
      "09557e3be39347e1b51b48efded150de",
      "b8e1236bf7544721831e10ee096ec8b9"
     ]
    },
    "executionInfo": {
     "elapsed": 29653,
     "status": "ok",
     "timestamp": 1691362762998,
     "user": {
      "displayName": "薛竣祐",
      "userId": "03276991785061169168"
     },
     "user_tz": -480
    },
    "id": "AlCmUoXbN_VA",
    "outputId": "ff50f08b-fb7b-4049-abd7-8e7eeb0cfb1b"
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2282032042.py, line 21)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [19]\u001b[0;36m\u001b[0m\n\u001b[0;31m    outputs = # TODO\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Evalation\n",
    "from utils_qa import post_processing_function, create_and_fill_np_array\n",
    "\n",
    "\n",
    "print(\"***** Running Evaluation *****\")\n",
    "print(f\"  Num examples = {len(eval_dataset)}\")\n",
    "print(f\"  Batch size = {args.per_device_eval_batch_size}\")\n",
    "print(f\"  squad_version = {metric.name}\")\n",
    "\n",
    "\n",
    "progress_bar = tqdm(range(len(eval_dataloader)), disable=not accelerator.is_local_main_process)\n",
    "\n",
    "model.eval()\n",
    "output_layer.eval()\n",
    "\n",
    "all_start_logits = []\n",
    "all_end_logits = []\n",
    "for step, batch in enumerate(eval_dataloader):\n",
    "    with torch.no_grad():\n",
    "        encoding = model(**batch)\n",
    "        outputs = output_layer(encoding['last_hidden_state'], batch['start_positions'], batch['end_positions']) # TODO\n",
    "        start_logits = outputs.start_logits\n",
    "        end_logits = outputs.end_logits\n",
    "\n",
    "        if not args.pad_to_max_length:  # 統一所有進程的padding長度才能使用accelerator.gather() Align the padding lengths of all processes in order to use accelerator.gather()\n",
    "            start_logits = accelerator.pad_across_processes(start_logits, dim=1, pad_index=-100) # pad tensor across processes to max length\n",
    "            end_logits = accelerator.pad_across_processes(end_logits, dim=1, pad_index=-100)\n",
    "\n",
    "        all_start_logits.append(accelerator.gather(start_logits).cpu().numpy()) # 分散式運算時用於集合預測結果 Aggregate prediction results when distributed computing\n",
    "        all_end_logits.append(accelerator.gather(end_logits).cpu().numpy())\n",
    "    progress_bar.update(1)\n",
    "\n",
    "max_len = max([x.shape[1] for x in all_start_logits])\n",
    "\n",
    "# concatenate array\n",
    "all_start_logits = create_and_fill_np_array(all_start_logits, eval_dataset, max_len)\n",
    "all_end_logits = create_and_fill_np_array(all_end_logits, eval_dataset, max_len)\n",
    "\n",
    "\n",
    "outputs_numpy = (all_start_logits, all_end_logits) # 預測結果 prediction result\n",
    "prediction = post_processing_function(datasets['validation'], eval_dataset, outputs_numpy,args) # 後處理 post-processing , ref: https://reurl.cc/ZW3XjM\n",
    "eval_metric = metric.compute(predictions=prediction.predictions, references=prediction.label_ids)\n",
    "print(f\"Evaluation metrics: {eval_metric}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 860,
     "status": "ok",
     "timestamp": 1691362763851,
     "user": {
      "displayName": "薛竣祐",
      "userId": "03276991785061169168"
     },
     "user_tz": -480
    },
    "id": "_CXamgAIzutl",
    "outputId": "4cb8e712-c77d-4b33-d1d9-760f6f63c74b"
   },
   "outputs": [],
   "source": [
    "# 觀察直接選擇start_logits和end_logits各自最大值的結果與經過post_processing_function處理過後的結果之間的差異\n",
    "# Check the difference between the result of choosing the maximum values of start_logits and end_logits directly and the result after post_processing_function.\n",
    "for qs_id in range(10):\n",
    "  start_idx = outputs_numpy[0][qs_id].argmax()\n",
    "  end_idx = outputs_numpy[1][qs_id].argmax()\n",
    "  print(f\"{start_idx}-{end_idx}\")\n",
    "  print(\" \".join(tokenizer.convert_ids_to_tokens(eval_dataset['input_ids'][qs_id][start_idx:end_idx+1])))\n",
    "  print(prediction.predictions[qs_id]['prediction_text'])\n",
    "  print('========')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1691362763851,
     "user": {
      "displayName": "薛竣祐",
      "userId": "03276991785061169168"
     },
     "user_tz": -480
    },
    "id": "odbwErUAtvJd",
    "outputId": "6493279c-a35e-4069-9f40-cc6607caa44e"
   },
   "outputs": [],
   "source": [
    "# 人工查看，比較預測結果與和答案\n",
    "# Manually check and compare predictions with ground truth\n",
    "\n",
    "for i in range(0, 500, 50):\n",
    "  print(\"----Question----\")\n",
    "  pp.pprint(datasets['validation'][i])\n",
    "  print(\"\\n----Prediction----\")\n",
    "  pp.pprint(prediction.predictions[i])\n",
    "  print(\"=\"*70+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Erpn9sR9nakL"
   },
   "outputs": [],
   "source": [
    "# 儲存微調好的模型\n",
    "# Save the fine-tuned model\n",
    "if args.output_dir is not None:\n",
    "    accelerator.wait_for_everyone()\n",
    "    unwrapped_model = accelerator.unwrap_model(model)\n",
    "    unwrapped_model.save_pretrained(args.output_dir, save_function=accelerator.save)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [
    {
     "file_id": "1OkTT7qhPWyFcPa9SwOwknY0PiEaSmsV7",
     "timestamp": 1691450826251
    },
    {
     "file_id": "1QlK7n7isFvPAK7YFzi55ZRMF36K0W-cs",
     "timestamp": 1691173596890
    },
    {
     "file_id": "196rCHRMmU6_2ew5yovnRJYbAxOxWdhtD",
     "timestamp": 1660803012097
    },
    {
     "file_id": "1V5Z0JSxgAqlbBEGsB1HsO1uKF1hqdrYf",
     "timestamp": 1629261820350
    },
    {
     "file_id": "https://github.com/fireindark707/BERT_code_example/blob/main/examples/question_answering.ipynb",
     "timestamp": 1626604049604
    }
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "014bf9be72fd4f629ff2fcc88efa9c69": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "09557e3be39347e1b51b48efded150de": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "09da23cc8e9349688a79d2c29a05a6c7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0cb440e7369a4702a9af9989bf441df9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ad5232729b534cd0aa4e766247b20c40",
       "IPY_MODEL_de0dfea5e6264cfaae7334b2ebcb0a8a",
       "IPY_MODEL_b7739956628948a4a7dec5a7102fcaee"
      ],
      "layout": "IPY_MODEL_ad118d3b74b449e9af2da40b08f126f7"
     }
    },
    "18b4801ced9b4e30a6d8f6c4e1de3e5e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_cbe73ae13fb849aca282e64ff908c23c",
       "IPY_MODEL_e5220750031d4e089c9ae5430130f262",
       "IPY_MODEL_5f75259418ab4964aa44345ac4c8d34e"
      ],
      "layout": "IPY_MODEL_a2e51565db724c5682756c24814679a9"
     }
    },
    "1a02b8505e384ebe9b3d1e82ca546b0f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "23095b6a962a4485b487cce7ae09af87": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2482fbfaafc14d699b38ea940f13e48e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2bc8fdf5bb21454bb99502539afa9d4c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "49080f24cf454143b1b3d6b160a982bf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "527974f6accb4501bb460eb7b6117551": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_5e893ab0c1d04738a7a7f44389a3e010",
       "IPY_MODEL_91bd03865250418fae5d9863756912d1",
       "IPY_MODEL_d3229be921d24abdbb0482bfa70bbce9"
      ],
      "layout": "IPY_MODEL_892bb743e7c042cda9d3f159a0f761ae"
     }
    },
    "5736c6520c704016a8f00cac6caba60f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5b2c553e26054ed5818582f315a4e0fc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_09da23cc8e9349688a79d2c29a05a6c7",
      "placeholder": "​",
      "style": "IPY_MODEL_8e316628178e4504a981dd725bd7274a",
      "value": "Running tokenizer on validation dataset (num_proc=4): 100%"
     }
    },
    "5e893ab0c1d04738a7a7f44389a3e010": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c0ee078fe02c4f19bc5991cf1ec4db68",
      "placeholder": "​",
      "style": "IPY_MODEL_addf7de6d66f4b2f99dbbf06f06ac6f3",
      "value": "100%"
     }
    },
    "5f75259418ab4964aa44345ac4c8d34e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9a7fc4d2ebdc47e0b3da10c232886182",
      "placeholder": "​",
      "style": "IPY_MODEL_dbed778fc2ff4b749fa3b3e027d14088",
      "value": " 250/250 [07:05&lt;00:00,  1.60s/it]"
     }
    },
    "6032afe69bea41bf939165f0a92b5373": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6f0a34df396f44f7b6de5eb7b778815a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7b47484c555747bca3aaf45f3ac67266": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "807f36c8143b4012adb402613e32185d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_5b2c553e26054ed5818582f315a4e0fc",
       "IPY_MODEL_e7d065453af54786b8d3716fb33de912",
       "IPY_MODEL_909602f7e6ac46da906df869cf12d1b5"
      ],
      "layout": "IPY_MODEL_c85b6855bd094b64982028e269bc0f2c"
     }
    },
    "8266258b51234fe480e6259c318ec284": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "842c593f0c3648bd934bb95848dd48db": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "869083dbde4d4313b6ef27825a5e8dba": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "892bb743e7c042cda9d3f159a0f761ae": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8e316628178e4504a981dd725bd7274a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "909602f7e6ac46da906df869cf12d1b5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8266258b51234fe480e6259c318ec284",
      "placeholder": "​",
      "style": "IPY_MODEL_9cbfd243e4c94a7e9b3fa8441e0804b1",
      "value": " 500/500 [00:03&lt;00:00, 246.57 examples/s]"
     }
    },
    "91bd03865250418fae5d9863756912d1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2482fbfaafc14d699b38ea940f13e48e",
      "max": 32,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_842c593f0c3648bd934bb95848dd48db",
      "value": 32
     }
    },
    "9a7fc4d2ebdc47e0b3da10c232886182": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9b1761ce967240b8b97d3af03b188a74": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9cbfd243e4c94a7e9b3fa8441e0804b1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a2e51565db724c5682756c24814679a9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a3103ec77d8b4a379e5cf5ca338dc6c5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a6194a2f36ad4a1a80ef5f778b56a702": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e360148e58fe4523a6a724a511990584",
       "IPY_MODEL_b4062756718a4e599936154d925495aa",
       "IPY_MODEL_a75a170085f046a39ac98219c87881f4"
      ],
      "layout": "IPY_MODEL_f4a1e21bf914467297357514111a0a07"
     }
    },
    "a75a170085f046a39ac98219c87881f4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d5f51cabee4b41a9920aaa89eb101cca",
      "placeholder": "​",
      "style": "IPY_MODEL_1a02b8505e384ebe9b3d1e82ca546b0f",
      "value": " 4000/4000 [00:04&lt;00:00, 954.92 examples/s]"
     }
    },
    "a9be2beb2e9a4dab887aae4c7141aa19": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ad118d3b74b449e9af2da40b08f126f7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ad5232729b534cd0aa4e766247b20c40": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7b47484c555747bca3aaf45f3ac67266",
      "placeholder": "​",
      "style": "IPY_MODEL_23095b6a962a4485b487cce7ae09af87",
      "value": "100%"
     }
    },
    "addf7de6d66f4b2f99dbbf06f06ac6f3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b4062756718a4e599936154d925495aa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6032afe69bea41bf939165f0a92b5373",
      "max": 4000,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_869083dbde4d4313b6ef27825a5e8dba",
      "value": 4000
     }
    },
    "b41fb4576f854da5bd0fc3adb4274e46": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b7739956628948a4a7dec5a7102fcaee": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_09557e3be39347e1b51b48efded150de",
      "placeholder": "​",
      "style": "IPY_MODEL_b8e1236bf7544721831e10ee096ec8b9",
      "value": " 10570/10570 [00:05&lt;00:00, 7626.86it/s]"
     }
    },
    "b8e1236bf7544721831e10ee096ec8b9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ba1bd9516f2c48acaea8960d3cb3d860": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c0ee078fe02c4f19bc5991cf1ec4db68": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c666f8601b6c4f3fba3d327c3ee8173b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c85b6855bd094b64982028e269bc0f2c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cbe73ae13fb849aca282e64ff908c23c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dfb902be24b34fc5810aaaa92a7feec9",
      "placeholder": "​",
      "style": "IPY_MODEL_ba1bd9516f2c48acaea8960d3cb3d860",
      "value": "100%"
     }
    },
    "d3229be921d24abdbb0482bfa70bbce9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9b1761ce967240b8b97d3af03b188a74",
      "placeholder": "​",
      "style": "IPY_MODEL_2bc8fdf5bb21454bb99502539afa9d4c",
      "value": " 32/32 [00:18&lt;00:00,  2.21it/s]"
     }
    },
    "d5f51cabee4b41a9920aaa89eb101cca": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dbed778fc2ff4b749fa3b3e027d14088": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "de0dfea5e6264cfaae7334b2ebcb0a8a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6f0a34df396f44f7b6de5eb7b778815a",
      "max": 10570,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a3103ec77d8b4a379e5cf5ca338dc6c5",
      "value": 10570
     }
    },
    "dfb902be24b34fc5810aaaa92a7feec9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e360148e58fe4523a6a724a511990584": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5736c6520c704016a8f00cac6caba60f",
      "placeholder": "​",
      "style": "IPY_MODEL_a9be2beb2e9a4dab887aae4c7141aa19",
      "value": "Running tokenizer on train dataset (num_proc=4): 100%"
     }
    },
    "e5220750031d4e089c9ae5430130f262": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_014bf9be72fd4f629ff2fcc88efa9c69",
      "max": 250,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_49080f24cf454143b1b3d6b160a982bf",
      "value": 250
     }
    },
    "e7d065453af54786b8d3716fb33de912": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c666f8601b6c4f3fba3d327c3ee8173b",
      "max": 500,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b41fb4576f854da5bd0fc3adb4274e46",
      "value": 500
     }
    },
    "f4a1e21bf914467297357514111a0a07": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
