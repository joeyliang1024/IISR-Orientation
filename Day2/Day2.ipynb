{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J0Qjg6vuaHNt"
   },
   "source": [
    "# Neural machine translation with attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JsDyBLwVlVUn",
    "outputId": "1c625b8d-eeb2-461e-8eae-985431cdbab5"
   },
   "outputs": [],
   "source": [
    "#!pip uninstall torch -y\n",
    "#!pip install torch==2.0.1 torchvision==0.15.2 torchaudio==2.0.2\n",
    "#!pip install torchtext #==0.15.2\n",
    "#!pip install opencc==1.1.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tnxXKDjq3jEL",
    "outputId": "2473e38e-aa4b-4cde-bea7-9f92bedeeb9b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.1+cu117\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wfodePkj3jEa"
   },
   "source": [
    "## Download and prepare the dataset\n",
    "\n",
    "We'll use a language dataset provided by http://www.manythings.org/anki/. This dataset contains language translation pairs in the format:\n",
    "\n",
    "```\n",
    "The cat is adorable.\t這隻貓很可愛。\n",
    "```\n",
    "\n",
    "There are a variety of languages available, but we'll use the English-Ｍandarin dataset. For convenience, we've hosted a copy of this dataset on Google Cloud, but you can also download your own copy. After downloading the dataset, here are the steps we'll take to prepare the data:\n",
    "\n",
    "1. Add a *start* and *end* token to each sentence.\n",
    "2. Clean the sentences by removing special characters.\n",
    "3. Create a word index and reverse word index (dictionaries mapping from word → id and id → word).\n",
    "4. Pad each sentence to a maximum length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "YYZ8pxw-H0os"
   },
   "outputs": [],
   "source": [
    "from urllib.request import Request, urlopen\n",
    "from io import BytesIO\n",
    "from zipfile import ZipFile\n",
    "import os\n",
    "zip_url = 'https://www.manythings.org/anki/cmn-eng.zip'\n",
    "txt_name = 'cmn.txt'\n",
    "\n",
    "def read_txt_from_zip_url(url, read_txt_name) -> str:\n",
    "    req = Request(url)\n",
    "    req.add_header('user-agent', '')  # Set a user-agent to prevent 406 error (Not Acceptable)\n",
    "    response = urlopen(req)\n",
    "\n",
    "    with response as resp:\n",
    "        with BytesIO(resp.read()) as b, ZipFile(b) as zip_file:\n",
    "            txt_file = zip_file.open(read_txt_name)\n",
    "            text_str = txt_file.read().decode('utf8')\n",
    "\n",
    "    return text_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Onf4YTbKVN32",
    "outputId": "ce1acd32-bd77-47d4-93ed-4ba5247b71ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load txt\n",
      "\n",
      "Hi.\t嗨。\tCC-BY 2.0 (France) Attribution: tatoeba.org #538123 (CM) & #891077 (Martha)\n",
      "Hi.\t你好。\tCC-BY 2.0 (France) Attribution: tatoeba.org #538123 (CM) & #4857568 (musclegirlxyp)\n",
      "Run.\t你用跑的。\tCC-BY 2.0 (France) Attribution: tatoeba.org #4008918 (JSakuragi) & #3748344 (egg0073)\n",
      "Stop!\t住手！\tCC-BY 2.0 (France) Attribution: tatoeba.org #448320 (CM) & #448321 (GlossaMatik)\n",
      "Wait!\t等等！\tCC-BY 2.0 (France) Attribution: tatoeba.org #1744314 (belgavox) & #4970122 (wzhd)\n",
      "Wait!\t等一下！\tCC-BY 2.0 (France) Attribution: ta\n"
     ]
    }
   ],
   "source": [
    "if txt_name in os.listdir():\n",
    "    print(\"load txt\\n\")\n",
    "    with open(txt_name, encoding='utf8') as file:\n",
    "        text = file.read()\n",
    "else:\n",
    "    text = read_txt_from_zip_url(zip_url, txt_name)\n",
    "    with open(txt_name, 'w', encoding='utf8') as file:\n",
    "        file.write(text)\n",
    "    print(\"saved txt\\n\")\n",
    "\n",
    "print(text[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5cOV_ijB977n"
   },
   "source": [
    "##Tokenization\n",
    "Tokenization is the process of breaking down sentences or phrases into individual words or tokens.\n",
    "\n",
    "In this example, different tokenization methods are applied to English and Chinese texts, respectively.\n",
    "\n",
    "In both cases, the output requires the addition of '\\<sos>' (start of sentence) and '\\<eos>' (end of sentence) tokens at the beginning and the end of the tokenized sequences, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CuGjhFGEOr3Q",
    "outputId": "7bbef043-37d5-49dd-be80-118b15231764"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-06 12:53:11.440851: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-06 12:53:11.630259: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-08-06 12:53:12.124109: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:\n",
      "2023-08-06 12:53:12.124202: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:\n",
      "2023-08-06 12:53:12.124212: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'cat', 'is', 'adorable', '.']\n",
      "['這', '隻', '貓', '很', '可', '愛', '。']\n",
      "\n",
      "['<sos>', 'the', 'cat', 'is', 'adorable', '.', '<eos>']\n",
      "['<sos>', '這', '隻', '貓', '很', '可', '愛', '。', '<eos>']\n"
     ]
    }
   ],
   "source": [
    "from torchtext.data.utils import get_tokenizer\n",
    "\n",
    "def tokenizer_decorator(tokenizer):\n",
    "    \"\"\"Add <sos> and <eos>\"\"\"\n",
    "    def new_tokenizer(*args, **kw):\n",
    "        output = tokenizer(*args, **kw)\n",
    "        return ['<sos>'] + output + ['<eos>']\n",
    "    return new_tokenizer\n",
    "\n",
    "en_tokenizer = get_tokenizer('basic_english')\n",
    "zh_tokenizer = list\n",
    "\n",
    "print(en_tokenizer(\"The cat is adorable.\"))\n",
    "print(zh_tokenizer(\"這隻貓很可愛。\"))\n",
    "\n",
    "en_tokenizer = tokenizer_decorator(en_tokenizer)\n",
    "zh_tokenizer = tokenizer_decorator(zh_tokenizer)\n",
    "\n",
    "print()\n",
    "print(en_tokenizer(\"The cat is adorable.\"))\n",
    "print(zh_tokenizer(\"這隻貓很可愛。\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qb7D6Pw6xanG"
   },
   "source": [
    "### Limit the size of the dataset to experiment faster (optional)\n",
    "Training on the complete dataset of >25,000 sentences will take a long time. To train faster, we can limit the size of the dataset to 10,000 sentences (of course, translation quality degrades with less data):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qVjS7xNRdtY-",
    "outputId": "afc8def1-6246-4d70-9cb0-74a1c9795e5d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[['<sos>', 'hi', '.', '<eos>'], ['<sos>', 'hi', '.', '<eos>'], ['<sos>', 'run', '.', '<eos>'], ['<sos>', 'stop', '!', '<eos>'], ['<sos>', 'wait', '!', '<eos>']]\n",
      "[['<sos>', '嗨', '。', '<eos>'], ['<sos>', '你', '好', '。', '<eos>'], ['<sos>', '你', '用', '跑', '的', '。', '<eos>'], ['<sos>', '住', '手', '！', '<eos>'], ['<sos>', '等', '等', '！', '<eos>']]\n"
     ]
    }
   ],
   "source": [
    "train_num, valid_num = 80000, 20000\n",
    "data = text.split('\\n')[:train_num+valid_num]\n",
    "\n",
    "en_data, zh_data = [], []\n",
    "for line in data:\n",
    "    try:\n",
    "        en_sentence, zh_sentence = line.split('\\t')[:2]\n",
    "        en_data.append(en_tokenizer(en_sentence))\n",
    "        zh_data.append(zh_tokenizer(zh_sentence))\n",
    "    except:\n",
    "        print(line)\n",
    "\n",
    "print(en_data[:5])\n",
    "print(zh_data[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uavqLgfwhD-C",
    "outputId": "6d75459c-62c1-4d71-dcad-5e4d99762eba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of the en_vocab is: 7178\n",
      "The index of '<sos>' is: 0\n",
      "The token at index 2 is: <pad>\n",
      "The token at index 5 is: run\n",
      "\n",
      "The length of the zh_vocab is: 3650\n",
      "The index of '<sos>' is: 0\n",
      "The token at index 2 is: <pad>\n",
      "The token at index 5 is: 你\n",
      "\n",
      "The length of the longest sequence: 46\n"
     ]
    }
   ],
   "source": [
    "from torchtext.vocab import vocab\n",
    "from itertools import chain\n",
    "from collections import Counter\n",
    "\n",
    "en_counter = Counter(chain.from_iterable(en_data))\n",
    "en_vocab = vocab(en_counter, specials=('<sos>', '<eos>', '<pad>'))\n",
    "zh_counter = Counter(chain.from_iterable(zh_data))\n",
    "zh_vocab = vocab(zh_counter, specials=('<sos>', '<eos>', '<pad>'))\n",
    "\n",
    "print(\"The length of the en_vocab is:\", len(en_vocab))\n",
    "en_stoi = en_vocab.get_stoi()\n",
    "print(\"The index of '<sos>' is:\", en_stoi['<sos>'])\n",
    "en_itos = en_vocab.get_itos()\n",
    "print(\"The token at index 2 is:\", en_itos[2])\n",
    "print(\"The token at index 5 is:\", en_itos[5])\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"The length of the zh_vocab is:\", len(zh_vocab))\n",
    "zh_stoi = zh_vocab.get_stoi()\n",
    "print(\"The index of '<sos>' is:\", zh_stoi['<sos>'])\n",
    "zh_itos = zh_vocab.get_itos()\n",
    "print(\"The token at index 2 is:\", zh_itos[2])\n",
    "print(\"The token at index 5 is:\", zh_itos[5])\n",
    "print()\n",
    "\n",
    "max_length = max(map(len, en_data + zh_data))\n",
    "print(\"The length of the longest sequence:\", max_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eJKjRfX6qw8a"
   },
   "source": [
    "## Preparing your data for training with Dataset & DataLoader\n",
    "While training a model, we typically want to pass samples in “mini-batches”, reshuffle the data at every epoch to reduce model overfitting.\n",
    "\n",
    "A custom **Dataset** class must implement three functions: **\\_\\_init__**, **\\_\\_getitem__**., and **\\_\\_len__**.\n",
    "\n",
    "**DataLoader** is an iterable that abstracts this complexity for us in an easy API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "QDVk-ad_23lU"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "class TranslateDataset(Dataset):\n",
    "    def __init__(self, inp_data, tar_data):\n",
    "        self.inp_data = inp_data\n",
    "        self.tar_data = tar_data\n",
    "        self._len = len(inp_data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.inp_data[index], self.tar_data[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self._len\n",
    "\n",
    "def collate_batch(batch):\n",
    "    inp_sequences, tar_sequences = zip(*batch)\n",
    "\n",
    "    max_length_inp = max(map(len, inp_sequences))\n",
    "    max_length_tar = max(map(len, tar_sequences))\n",
    "    max_length = max(max_length_inp, max_length_tar)\n",
    "\n",
    "    padded_inp_sequences = [seq + ['<pad>'] * (max_length - len(seq)) for seq in inp_sequences]\n",
    "    padded_tar_sequences = [seq + ['<pad>'] * (max_length - len(seq)) for seq in tar_sequences]\n",
    "\n",
    "    return padded_inp_sequences, padded_tar_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "__g-8OY-M7ic"
   },
   "source": [
    "### Here we simply take the first 8,000 data for training, and the last 2,000 data for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4rUypSi5tf4C",
    "outputId": "7840d895-9f47-4b4f-f957-594393c4e657"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['<sos>', 'hi', '.', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>'], ['<sos>', 'hi', '.', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>'], ['<sos>', 'run', '.', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>'], ['<sos>', 'stop', '!', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>'], ['<sos>', 'wait', '!', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>'], ['<sos>', 'wait', '!', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>'], ['<sos>', 'begin', '.', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>'], ['<sos>', 'hello', '!', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>'], ['<sos>', 'i', 'try', '.', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>'], ['<sos>', 'i', 'won', '!', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>'], ['<sos>', 'oh', 'no', '!', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>'], ['<sos>', 'cheers', '!', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>'], ['<sos>', 'got', 'it', '?', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>'], ['<sos>', 'got', 'it', '?', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>'], ['<sos>', 'got', 'it', '?', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>'], ['<sos>', 'he', 'ran', '.', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>'], ['<sos>', 'hop', 'in', '.', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>'], ['<sos>', 'i', 'know', '.', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>'], ['<sos>', 'i', 'quit', '.', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>'], ['<sos>', 'i', 'quit', '.', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>'], ['<sos>', 'i', \"'\", 'm', 'ok', '.', '<eos>', '<pad>', '<pad>'], ['<sos>', 'i', \"'\", 'm', 'up', '.', '<eos>', '<pad>', '<pad>'], ['<sos>', 'listen', '.', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>'], ['<sos>', 'no', 'way', '!', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>'], ['<sos>', 'no', 'way', '!', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>'], ['<sos>', 'really', '?', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>'], ['<sos>', 'thanks', '!', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>'], ['<sos>', 'try', 'it', '.', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>'], ['<sos>', 'we', 'try', '.', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>'], ['<sos>', 'why', 'me', '?', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>'], ['<sos>', 'ask', 'tom', '.', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>'], ['<sos>', 'awesome', '!', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>'], ['<sos>', 'be', 'calm', '.', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>'], ['<sos>', 'be', 'fair', '.', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>'], ['<sos>', 'be', 'kind', '.', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>'], ['<sos>', 'be', 'kind', '.', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>'], ['<sos>', 'be', 'nice', '.', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>'], ['<sos>', 'be', 'nice', '.', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>'], ['<sos>', 'call', 'me', '.', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>'], ['<sos>', 'call', 'us', '.', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>'], ['<sos>', 'come', 'in', '.', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>'], ['<sos>', 'get', 'tom', '.', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>'], ['<sos>', 'get', 'out', '!', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>'], ['<sos>', 'get', 'out', '!', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>'], ['<sos>', 'go', 'away', '!', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>'], ['<sos>', 'go', 'away', '!', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>'], ['<sos>', 'go', 'away', '.', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>'], ['<sos>', 'go', 'home', '.', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>'], ['<sos>', 'go', 'home', '.', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>'], ['<sos>', 'goodbye', '!', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>'], ['<sos>', 'goodbye', '!', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>'], ['<sos>', 'hang', 'on', '!', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>'], ['<sos>', 'hang', 'on', '!', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>'], ['<sos>', 'hang', 'on', '.', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>'], ['<sos>', 'he', 'came', '.', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>'], ['<sos>', 'he', 'runs', '.', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>'], ['<sos>', 'help', 'me', '.', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>'], ['<sos>', 'help', 'us', '.', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>'], ['<sos>', 'hit', 'tom', '.', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>'], ['<sos>', 'hold', 'on', '.', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>'], ['<sos>', 'hug', 'tom', '.', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>'], ['<sos>', 'hug', 'tom', '.', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>'], ['<sos>', 'i', 'agree', '.', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>'], ['<sos>', 'i', \"'\", 'm', 'hot', '.', '<eos>', '<pad>', '<pad>']]\n",
      "[['<sos>', '嗨', '。', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>'], ['<sos>', '你', '好', '。', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>'], ['<sos>', '你', '用', '跑', '的', '。', '<eos>', '<pad>', '<pad>'], ['<sos>', '住', '手', '！', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>'], ['<sos>', '等', '等', '！', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>'], ['<sos>', '等', '一', '下', '！', '<eos>', '<pad>', '<pad>', '<pad>'], ['<sos>', '开', '始', '！', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>'], ['<sos>', '你', '好', '。', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>'], ['<sos>', '我', '试', '试', '。', '<eos>', '<pad>', '<pad>', '<pad>'], ['<sos>', '我', '赢', '了', '。', '<eos>', '<pad>', '<pad>', '<pad>'], ['<sos>', '不', '会', '吧', '。', '<eos>', '<pad>', '<pad>', '<pad>'], ['<sos>', '乾', '杯', '!', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>'], ['<sos>', '知', '道', '了', '没', '有', '？', '<eos>', '<pad>'], ['<sos>', '懂', '了', '吗', '？', '<eos>', '<pad>', '<pad>', '<pad>'], ['<sos>', '你', '懂', '了', '吗', '？', '<eos>', '<pad>', '<pad>'], ['<sos>', '他', '跑', '了', '。', '<eos>', '<pad>', '<pad>', '<pad>'], ['<sos>', '跳', '进', '来', '。', '<eos>', '<pad>', '<pad>', '<pad>'], ['<sos>', '我', '知', '道', '。', '<eos>', '<pad>', '<pad>', '<pad>'], ['<sos>', '我', '退', '出', '。', '<eos>', '<pad>', '<pad>', '<pad>'], ['<sos>', '我', '不', '干', '了', '。', '<eos>', '<pad>', '<pad>'], ['<sos>', '我', '沒', '事', '。', '<eos>', '<pad>', '<pad>', '<pad>'], ['<sos>', '我', '已', '经', '起', '来', '了', '。', '<eos>'], ['<sos>', '听', '着', '。', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>'], ['<sos>', '不', '可', '能', '！', '<eos>', '<pad>', '<pad>', '<pad>'], ['<sos>', '没', '门', '！', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>'], ['<sos>', '你', '确', '定', '？', '<eos>', '<pad>', '<pad>', '<pad>'], ['<sos>', '谢', '谢', '！', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>'], ['<sos>', '试', '试', '吧', '。', '<eos>', '<pad>', '<pad>', '<pad>'], ['<sos>', '我', '们', '来', '试', '试', '。', '<eos>', '<pad>'], ['<sos>', '为', '什', '么', '是', '我', '？', '<eos>', '<pad>'], ['<sos>', '去', '问', '汤', '姆', '。', '<eos>', '<pad>', '<pad>'], ['<sos>', '好', '棒', '！', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>'], ['<sos>', '冷', '静', '点', '。', '<eos>', '<pad>', '<pad>', '<pad>'], ['<sos>', '公', '平', '点', '。', '<eos>', '<pad>', '<pad>', '<pad>'], ['<sos>', '友', '善', '点', '。', '<eos>', '<pad>', '<pad>', '<pad>'], ['<sos>', '友', '好', '點', '。', '<eos>', '<pad>', '<pad>', '<pad>'], ['<sos>', '和', '气', '点', '。', '<eos>', '<pad>', '<pad>', '<pad>'], ['<sos>', '友', '善', '点', '。', '<eos>', '<pad>', '<pad>', '<pad>'], ['<sos>', '联', '系', '我', '。', '<eos>', '<pad>', '<pad>', '<pad>'], ['<sos>', '联', '系', '我', '们', '。', '<eos>', '<pad>', '<pad>'], ['<sos>', '进', '来', '。', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>'], ['<sos>', '找', '到', '汤', '姆', '。', '<eos>', '<pad>', '<pad>'], ['<sos>', '滾', '出', '去', '！', '<eos>', '<pad>', '<pad>', '<pad>'], ['<sos>', '出', '去', '！', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>'], ['<sos>', '走', '開', '！', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>'], ['<sos>', '滾', '！', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>'], ['<sos>', '走', '開', '！', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>'], ['<sos>', '回', '家', '。', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>'], ['<sos>', '回', '家', '吧', '。', '<eos>', '<pad>', '<pad>', '<pad>'], ['<sos>', '再', '见', '！', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>'], ['<sos>', '告', '辞', '！', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>'], ['<sos>', '坚', '持', '。', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>'], ['<sos>', '等', '一', '下', '！', '<eos>', '<pad>', '<pad>', '<pad>'], ['<sos>', '坚', '持', '。', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>'], ['<sos>', '他', '来', '了', '。', '<eos>', '<pad>', '<pad>', '<pad>'], ['<sos>', '他', '跑', '。', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>'], ['<sos>', '帮', '我', '一', '下', '。', '<eos>', '<pad>', '<pad>'], ['<sos>', '帮', '帮', '我', '们', '吧', '！', '<eos>', '<pad>'], ['<sos>', '去', '打', '汤', '姆', '。', '<eos>', '<pad>', '<pad>'], ['<sos>', '坚', '持', '。', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>'], ['<sos>', '抱', '抱', '汤', '姆', '！', '<eos>', '<pad>', '<pad>'], ['<sos>', '请', '抱', '紧', '汤', '姆', '。', '<eos>', '<pad>'], ['<sos>', '我', '同', '意', '。', '<eos>', '<pad>', '<pad>', '<pad>'], ['<sos>', '我', '觉', '得', '很', '热', '。', '<eos>', '<pad>']]\n"
     ]
    }
   ],
   "source": [
    "train_dataset = TranslateDataset(en_data[:train_num], zh_data[:train_num])\n",
    "valid_dataset = TranslateDataset(en_data[-valid_num:], zh_data[-valid_num:])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=False, collate_fn=collate_batch)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=64, shuffle=False, collate_fn=collate_batch)\n",
    "\n",
    "for batch in train_loader:\n",
    "    print(*batch, sep='\\n')\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TNfHIF71ulLu"
   },
   "source": [
    "## Write the encoder and decoder model\n",
    "\n",
    "Implement an encoder-decoder model with attention which you can read about in the TensorFlow [Neural Machine Translation (seq2seq) tutorial](https://github.com/tensorflow/nmt). This example uses a more recent set of APIs. This notebook implements the [attention equations](https://github.com/tensorflow/nmt#background-on-the-attention-mechanism) from the seq2seq tutorial. The following diagram shows that each input words is assigned a weight by the attention mechanism which is then used by the decoder to predict the next word in the sentence. The below picture and formulas are an example of attention mechanism from [Luong's paper](https://arxiv.org/abs/1508.04025v5).\n",
    "\n",
    "<img src=\"https://www.tensorflow.org/images/seq2seq/attention_mechanism.jpg\" width=\"500\" alt=\"attention mechanism\">\n",
    "\n",
    "The input is put through an encoder model which gives us the encoder output of shape *(batch_size, max_length, hidden_size)* and the encoder hidden state of shape *(batch_size, hidden_size)*.\n",
    "\n",
    "Here are the equations that are implemented:\n",
    "\n",
    "<img src=\"https://www.tensorflow.org/images/seq2seq/attention_equation_0.jpg\" alt=\"attention equation 0\" width=\"800\">\n",
    "<img src=\"https://www.tensorflow.org/images/seq2seq/attention_equation_1.jpg\" alt=\"attention equation 1\" width=\"800\">\n",
    "\n",
    "This tutorial uses [Bahdanau attention](https://arxiv.org/pdf/1409.0473.pdf) for the encoder. Let's decide on notation before writing the simplified form:\n",
    "\n",
    "* FC = Fully connected (dense) layer\n",
    "* EO = Encoder output\n",
    "* H = hidden state\n",
    "* X = input to the decoder\n",
    "\n",
    "And the pseudo-code:\n",
    "\n",
    "* `score = FC(tanh(FC(EO) + FC(H)))`\n",
    "* `attention weights = softmax(score, axis = 1)`. Softmax by default is applied on the last axis but here we want to apply it on the *1st axis*, since the shape of score is *(batch_size, max_length, hidden_size)*. `Max_length` is the length of our input. Since we are trying to assign a weight to each input, softmax should be applied on that axis.\n",
    "* `context vector = sum(attention weights * EO, axis = 1)`. Same reason as above for choosing axis as 1.\n",
    "* `embedding output` = The input to the decoder X is passed through an embedding layer.\n",
    "* `merged vector = concat(embedding output, context vector)`\n",
    "* This merged vector is then given to the GRU\n",
    "\n",
    "The shapes of all the vectors at each step have been specified in the comments in the code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "WLBHKyKpMh0h"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, enc_units):\n",
    "        # vacab_size=src_vocab_size=1949, embedding_dim=256 enc_units=512\n",
    "        super(Encoder, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = nn.GRU(embedding_dim, enc_units)\n",
    "\n",
    "    def forward(self, x, hidden=None):\n",
    "        '''\n",
    "        Input:\n",
    "            ``x``\n",
    "            shape == (seq_length, batch_size)\n",
    "            dtype == tf.int64\n",
    "\n",
    "            ``hidden``\n",
    "            shape == (1, batch_size, enc_units) or None\n",
    "            dtype == tf.float32\n",
    "\n",
    "        Output:\n",
    "            ``h_e``\n",
    "            shape == (seq_length, batch_size, enc_units)\n",
    "\n",
    "            ``last_h_e``\n",
    "            shape == (1, batch_size, enc_units)\n",
    "        '''\n",
    "\n",
    "        # passing through embedding\n",
    "        # x shape == (seq_length, batch_size, embedding_dim) -> (seq_length, 64, 256)\n",
    "        x = self.embedding(x)\n",
    "\n",
    "        # passing x and hidden state to the GRU\n",
    "        # h_e shape == (seq_length, batch_size, enc_units) -> (seq_length, 64, 512)\n",
    "        # last_h_e shape == (1, batch_size, enc_units) -> (1, 64, 512)\n",
    "        h_e, last_h_e = self.gru(x, hidden)\n",
    "\n",
    "        # h_e contains the whole output of the sequence, last_h_e is the hidden state of the last timestamp\n",
    "        return h_e, last_h_e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1n2Nwukz4UJe",
    "outputId": "5ff5e6b6-8a29-478e-b210-4b8e39c408d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input shape == (seq_length, batch_size) -> torch.Size([10, 64])\n",
      "h_e shape == (seq_length, batch_size, units) -> torch.Size([10, 64, 512])\n",
      "last_h_e shape == (1, batch_size, units) -> torch.Size([1, 64, 512])\n",
      "tensor(True)\n"
     ]
    }
   ],
   "source": [
    "input_batch_tensor = torch.randint(low=0, high=1949, size=(10, 64))\n",
    "print('input shape == (seq_length, batch_size) ->', input_batch_tensor.shape)\n",
    "\n",
    "# build Encoder layer\n",
    "encoder = Encoder(vocab_size=1949, embedding_dim=256, enc_units=512)\n",
    "\n",
    "# test your code\n",
    "h_e, last_h_e = encoder(input_batch_tensor)\n",
    "print('h_e shape == (seq_length, batch_size, units) ->', h_e.shape)\n",
    "print('last_h_e shape == (1, batch_size, units) ->', last_h_e.shape)\n",
    "\n",
    "# show last_h_e is the hidden state of the last timestamp\n",
    "print(torch.any(h_e[-1,:,:] == last_h_e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "5SLxKE1yNBrC"
   },
   "outputs": [],
   "source": [
    "class BahdanauAttention(nn.Module):\n",
    "    def __init__(self, enc_units, dec_units, att_units):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        self.W1 = nn.Linear(dec_units, att_units)\n",
    "        self.W2 = nn.Linear(enc_units, att_units)\n",
    "        self.V = nn.Linear(att_units, 1)\n",
    "        self.softmax = nn.Softmax(1)\n",
    "\n",
    "    def score_function(self, h_d, h_e):\n",
    "        '''\n",
    "        Bahdanau's additive style:\n",
    "            score = V tanh( W1 h_d + W2 h_e )\n",
    "\n",
    "        Luong's multiplicative style:\n",
    "            score = h_d W h_e\n",
    "        '''\n",
    "        score = self.V(torch.tanh(self.W1(h_d)+self.W2(h_e)))\n",
    "        return score\n",
    "\n",
    "\n",
    "    def forward(self, h_d, h_e):\n",
    "        '''\n",
    "        Input:\n",
    "            ``h_d``\n",
    "            shape == (1, batch_size, dec_units)\n",
    "\n",
    "            ``h_e``\n",
    "            shape == (seq_length, batch_size, enc_units)\n",
    "\n",
    "        Output:\n",
    "            ``context_vector``\n",
    "            shape == (batch_size, enc_units)\n",
    "\n",
    "            ``attention_weights``\n",
    "            shape == (batch_size, seq_length, 1)\n",
    "        '''\n",
    "\n",
    "        # we are doing this to perform addition to calculate the score\n",
    "        # after permute h_d shape == (batch_size, 1, dec_units)\n",
    "        # after permute h_e shape == (batch_size, seq_length, enc_units)\n",
    "        h_d = h_d.permute(1, 0, 2)\n",
    "        h_e = h_e.permute(1, 0, 2)\n",
    "\n",
    "        # score shape == (batch_size, seq_length, 1) -> (64, seq_length, 1)\n",
    "        score = self.score_function(h_d, h_e)\n",
    "\n",
    "        # use softmax to normalize the score\n",
    "        # attention_weights shape == (batch_size, seq_length, 1) -> (64, seq_length, 1)\n",
    "        attention_weights = self.softmax(score)\n",
    "        \n",
    "        # context_vector = attention_weights * h_e\n",
    "        # context_vector shape == (batch_size, seq_length, enc_units) -> (64, seq_length, 512)\n",
    "        context_vector = attention_weights * h_e\n",
    "        \n",
    "        # sum up all h_e sequences\n",
    "        # context_vector shape after sum == (batch_size, enc_units) -> (64, 512)\n",
    "        context_vector = torch.sum(context_vector, dim=1)\n",
    "        return context_vector, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b0f1aUO16kIw",
    "outputId": "64c12196-cda6-4be9-d924-2d55b755dce8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h_d shape == (1, batch_size, units) -> torch.Size([1, 64, 512])\n",
      "context vector shape == (batch_size, units) -> torch.Size([64, 512])\n",
      "attention weights shape == (batch_size, seq_length, 1) -> torch.Size([64, 10, 1])\n"
     ]
    }
   ],
   "source": [
    "h_d = torch.randn(size=(1, 64, 512))\n",
    "print('h_d shape == (1, batch_size, units) ->', h_d.shape)\n",
    "\n",
    "# build BahdanauAttention layer\n",
    "attention = BahdanauAttention(enc_units=512, dec_units=512, att_units=512)\n",
    "\n",
    "# test your code\n",
    "context_vector, attention_weights = attention(h_d, h_e)\n",
    "print('context vector shape == (batch_size, units) ->', context_vector.shape)\n",
    "print('attention weights shape == (batch_size, seq_length, 1) ->', attention_weights.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "g5dkx3BaNVLH"
   },
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, enc_units, dec_units, attention):\n",
    "        # vocab_size=tar_vocab_size=1831, embedding_dim=256, dec_units=512\n",
    "        super(Decoder, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = nn.GRU(embedding_dim + enc_units, dec_units)\n",
    "\n",
    "        # the dimension of the output is the vocab size, through the softmax function,\n",
    "        # this layer will return the probability of each word in the dictory\n",
    "        self.fc = nn.Linear(dec_units, vocab_size)\n",
    "\n",
    "        # used for attention\n",
    "        self.attention = attention\n",
    "\n",
    "    def forward(self, x, hidden, enc_output):\n",
    "        '''\n",
    "            This function outputs a result at each timestamp.\n",
    "            The length of each sentence is 1. (previous word)\n",
    "\n",
    "        Input:\n",
    "            ``x``\n",
    "            shape == (1, batch_size)\n",
    "            dtype == tf.int64\n",
    "\n",
    "            ``hidden``\n",
    "            shape == (1, batch_size, dec_units)\n",
    "\n",
    "            ``enc_output``\n",
    "            shape == (seq_length, batch_size, enc_units)\n",
    "\n",
    "        Output:\n",
    "            ``output``\n",
    "            shape == (batch_size, vocab)\n",
    "\n",
    "            ``state``\n",
    "            shape == (1, batch_size, dec_units)\n",
    "\n",
    "            ``attention_weights``\n",
    "            shape == (batch_size, max_length, 1)\n",
    "        '''\n",
    "        # passing through embedding\n",
    "        # x shape == (seq_length, batch_size, embedding_dim) -> (1, 64, 256)\n",
    "        x = self.embedding(x)\n",
    "\n",
    "        # The hidden state of fisrt timestamp in the decoder is the hidden state of last timestamp in the encoder\n",
    "        # context_vector shape == (batch_size, enc_units) -> (64, 512)\n",
    "        context_vector, attention_weights = self.attention(hidden, enc_output)\n",
    "        # resize the context_vector shape == (1, batch_size, enc_units) -> (1, 64, 512)\n",
    "        context_vector = context_vector.unsqueeze(0)\n",
    "\n",
    "        # concatenate the input x and the context_vector\n",
    "        # after concatenation, x shape == (1, batch_size, embedding_dim + enc_units) -> (1, 64, 256 + 512)\n",
    "        x = torch.cat((x, context_vector), dim=2)\n",
    "\n",
    "        # passing the concatenated vector to the GRU\n",
    "        # output shape == (1, batch_size, dec_units) -> (1, 64, 512)\n",
    "        # state shape == (1, batch_size, dec_units) -> (1, 64, 512)\n",
    "        output, state = self.gru(x)\n",
    "\n",
    "        # resize the output shape == (batch_size, dec_units) -> (64, 512)\n",
    "        output = output.squeeze()\n",
    "\n",
    "        # passing through a linear layer\n",
    "        # output shape == (batch_size, vocab) -> (64, 1831)\n",
    "        x = self.fc(output)\n",
    "\n",
    "        return x, state, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5eC1NPZx9EF2",
    "outputId": "fee285a5-b0d5-4683-b66f-71a881ac23e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target shape == (seq_length, batch_size) -> torch.Size([1, 64])\n",
      "output shape == (batch_size, vocab) -> torch.Size([64, 1831])\n",
      "state shape == (1, batch_size, units) -> torch.Size([1, 64, 512])\n"
     ]
    }
   ],
   "source": [
    "target_batch_tensor = torch.zeros(size=(1, 64), dtype=torch.int64)\n",
    "print('target shape == (seq_length, batch_size) ->', target_batch_tensor.shape)\n",
    "\n",
    "# build Decoder layer\n",
    "decoder = Decoder(vocab_size=1831, embedding_dim=256, enc_units=512, dec_units=512, attention=attention)\n",
    "\n",
    "# test your code\n",
    "output, state, _ = decoder(target_batch_tensor, h_d, h_e)\n",
    "print('output shape == (batch_size, vocab) ->', output.shape)\n",
    "print('state shape == (1, batch_size, units) ->', state.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mU3Ce8M6I3rz"
   },
   "source": [
    "## Translator\n",
    "\n",
    "* The evaluate function is similar to the training loop, except we don't use *teacher forcing* here. The input to the decoder at each time step is its previous predictions along with the hidden state and the encoder output.\n",
    "* Stop predicting when the model predicts the *end token*.\n",
    "* And store the *attention weights for every time step*.\n",
    "\n",
    "Note: The encoder output is calculated only once for one input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "TB0lm8HkSodC"
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "\n",
    "class Translator(nn.Module):\n",
    "    def __init__(self, config, inp_vocab, tar_vocab, loss_fn):\n",
    "        super(Translator, self).__init__()\n",
    "        self.__dict__.update(config)\n",
    "\n",
    "        self.inp_stoi = inp_vocab.get_stoi()\n",
    "        self.tar_stoi = tar_vocab.get_stoi()\n",
    "        self.tar_itos = tar_vocab.get_itos()\n",
    "\n",
    "        self.attention = BahdanauAttention(self.enc_units, self.dec_units, self.att_units)\n",
    "        self.encoder = Encoder(self.src_vocab_size, self.src_emb_dim, self.enc_units)\n",
    "        self.decoder = Decoder(self.tar_vocab_size, self.tar_emb_dim, self.enc_units, self.dec_units, self.attention)\n",
    "        self.optimizer = optim.Adam(list(self.encoder.parameters()) + list(self.decoder.parameters()), lr=self.learning_rate)\n",
    "        self.loss_fn = loss_fn\n",
    "\n",
    "\n",
    "    def train_step(self, inp, tar, use_teacher_forcing=False):\n",
    "        \"\"\"\n",
    "        1. Pass the input through the encoder which return encoder output and the encoder hidden state.\n",
    "        2. The encoder output, encoder hidden state and the decoder input (which is the start token) is passed to the decoder.\n",
    "        3. The decoder returns the predictions and the decoder hidden state.\n",
    "        4. The decoder hidden state is then passed back into the model and the predictions are used to calculate the loss.\n",
    "        5. Use teacher forcing to decide the next input to the decoder.\n",
    "        6. Teacher forcing is the technique where the target word is passed as the next input to the decoder.\n",
    "        7. The final step is to calculate the gradients and apply it to the optimizer and backpropagate.\n",
    "        \"\"\"\n",
    "\n",
    "        # feed the <sos> as the first input of the decoder\n",
    "        dec_input = torch.LongTensor([self.tar_stoi['<sos>']] * len(tar[0])).unsqueeze(0).to('cuda')\n",
    "\n",
    "        enc_output, hidden = self.encoder(inp)\n",
    "\n",
    "        loss = 0\n",
    "        # Teacher forcing - feeding the target as the next input\n",
    "        for t in range(1, tar.shape[0]):\n",
    "            # passing enc_output to the decoder\n",
    "            pred, hidden, _ = self.decoder(dec_input, hidden, enc_output)\n",
    "\n",
    "            # predictions shape == (vocab_size, batch_size) -> (1831, 64)\n",
    "            loss += self.loss_fn(pred, tar[t, :])\n",
    "\n",
    "            # using teacher forcing\n",
    "            if use_teacher_forcing:\n",
    "                # (1, batch_size)\n",
    "                dec_input = tar[t, :].unsqueeze(0)\n",
    "            else:\n",
    "                dec_input = torch.argmax(pred, dim=0).unsqueeze(0)\n",
    "\n",
    "        batch_loss = loss.item() / tar.shape[0]\n",
    "\n",
    "        self.optimizer.zero_grad()\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        self.optimizer.step()\n",
    "\n",
    "        return batch_loss\n",
    "    \n",
    "    def evaluate_step(self, inp, tar, use_teacher_forcing=False):\n",
    "        # feed the <sos> as the first input of the decoder\n",
    "        dec_input = torch.LongTensor([self.tar_stoi['<sos>']] * len(tar[0])).unsqueeze(0).to('cuda')\n",
    "\n",
    "        enc_output, hidden = self.encoder(inp)\n",
    "\n",
    "        loss = 0\n",
    "        # Teacher forcing - feeding the target as the next input\n",
    "        for t in range(1, tar.shape[0]):\n",
    "            # passing enc_output to the decoder\n",
    "            pred, hidden, _ = self.decoder(dec_input, hidden, enc_output)\n",
    "\n",
    "            # predictions shape == (vocab_size, batch_size) -> (1831, 64)\n",
    "            loss += self.loss_fn(pred, tar[t, :])\n",
    "\n",
    "            # using teacher forcing\n",
    "            if use_teacher_forcing:\n",
    "                # (1, batch_size)\n",
    "                dec_input = tar[t, :].unsqueeze(0)\n",
    "            else:\n",
    "                dec_input = torch.argmax(pred, dim=0).unsqueeze(0)\n",
    "\n",
    "        batch_loss = loss.item() / tar.shape[0]\n",
    "        return batch_loss\n",
    "    \n",
    "    def translate(self, en_sentence):\n",
    "        with torch.no_grad():\n",
    "            en_sentence = en_tokenizer(en_sentence)\n",
    "            inputs = [self.inp_stoi[s] for s in en_sentence]\n",
    "            inputs = torch.LongTensor(inputs).unsqueeze(-1).to('cuda')\n",
    "\n",
    "            result = ['<sos>']\n",
    "\n",
    "            # enc out shape == (1, max_length_inp, 1024) -> (1, 46, 1024)\n",
    "            # enc hidden shape == (1, 1024)\n",
    "            enc_out, enc_hidden = self.encoder(inputs)\n",
    "\n",
    "            dec_hidden = enc_hidden\n",
    "            dec_input = torch.LongTensor([self.tar_stoi['<sos>']]).unsqueeze(0).to('cuda')\n",
    "\n",
    "            for t in range(20):\n",
    "\n",
    "                predictions, dec_hidden, attention_weights = self.decoder(dec_input, dec_hidden, enc_out)\n",
    "\n",
    "                # get the index which has the highest probability\n",
    "                predicted_id = torch.argmax(predictions)\n",
    "                # convert the index to the word\n",
    "                word = self.tar_itos[predicted_id]\n",
    "                result.append(word)\n",
    "\n",
    "                # when the decoder predicts the end, stop prediction\n",
    "                if word == '<eos>':\n",
    "                    return result, en_sentence\n",
    "\n",
    "                # the predicted id is fed back into the model\n",
    "                dec_input = torch.LongTensor([predicted_id]).unsqueeze(0).to('cuda')\n",
    "\n",
    "            return result, en_sentence\n",
    "\n",
    "\n",
    "    def evaluate(self, inp_sent, tar_sent):\n",
    "        translated, inp_sent = self.translate(inp_sent)\n",
    "        tar_sent = zh_tokenizer(tar_sent)\n",
    "        bleu = sentence_bleu([tar_sent], translated, weights=(0.25, 0.25, 0.25, 0.25))\n",
    "\n",
    "        return bleu, ' '.join(translated), ' '.join(inp_sent)\n",
    "\n",
    "\n",
    "    def save_model(self, filename='translator.pt'):\n",
    "        try:\n",
    "            os.makedirs(self.checkpoint_dir)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        torch.save({\n",
    "            'encoder_state_dict': self.encoder.state_dict(),\n",
    "            'decoder_state_dict': self.decoder.state_dict(),\n",
    "            'optimizer_state_dict': self.optimizer.state_dict(),\n",
    "        }, os.path.join(self.checkpoint_dir, filename))\n",
    "\n",
    "\n",
    "    def load_model(self, filename='translator.pt'):\n",
    "        try:\n",
    "            path = os.path.join(self.checkpoint_dir, filename)\n",
    "            checkpoint = torch.load(path)\n",
    "\n",
    "            self.encoder.load_state_dict(checkpoint['encoder_state_dict'])\n",
    "            self.decoder.load_state_dict(checkpoint['decoder_state_dict'])\n",
    "            self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "\n",
    "        except Exception as e:\n",
    "            print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qjmci_CpOdFB"
   },
   "source": [
    "## Define the loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "y24OZSb0OgIQ"
   },
   "outputs": [],
   "source": [
    "# When calculating the loss value, ignore all the <pad> tags in the target.\n",
    "ignore_index = zh_stoi['<pad>']\n",
    "loss_fn = nn.CrossEntropyLoss(ignore_index=ignore_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hpObfY22IddU"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "nWZLYYaHfKFZ"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook\n",
    "\n",
    "def train(translator, train_loader, valid_loader, config, use_teacher_forcing=True):\n",
    "    inp_stoi = translator.inp_stoi\n",
    "    tar_stoi = translator.tar_stoi\n",
    "    for epoch in range(config['epochs']):\n",
    "        total_loss = 0\n",
    "        eval_total_loss = 0\n",
    "\n",
    "        tn = tqdm_notebook(total=len(train_loader))\n",
    "        tn.set_description('Epoch: {}/{}'.format(epoch + 1, config['epochs']))\n",
    "        \n",
    "        # train\n",
    "        for batch in train_loader:\n",
    "            inp_sentences, tar_sentences = batch\n",
    "\n",
    "            inp = torch.LongTensor(\n",
    "                [list(map(inp_stoi.__getitem__, sentence)) for sentence in zip(*inp_sentences)]\n",
    "            ).to('cuda')\n",
    "            tar = torch.LongTensor(\n",
    "                [list(map(tar_stoi.__getitem__, sentence)) for sentence in zip(*tar_sentences)]\n",
    "            ).to('cuda')\n",
    "\n",
    "\n",
    "            batch_loss = translator.train_step(inp, tar, use_teacher_forcing)\n",
    "            total_loss += batch_loss\n",
    "\n",
    "            tn.set_postfix(loss=batch_loss)\n",
    "            tn.update(n=1)\n",
    "        \n",
    "        # evalute\n",
    "        with torch.no_grad():\n",
    "            for batch in valid_loader:\n",
    "                inp_sentences, tar_sentences = batch\n",
    "                inp = torch.LongTensor(\n",
    "                    [list(map(inp_stoi.__getitem__, sentence)) for sentence in zip(*inp_sentences)]\n",
    "                ).to('cuda')\n",
    "                tar = torch.LongTensor(\n",
    "                    [list(map(tar_stoi.__getitem__, sentence)) for sentence in zip(*tar_sentences)]\n",
    "                ).to('cuda')\n",
    "                eval_batch_loss = translator.evaluate_step(inp, tar, use_teacher_forcing)\n",
    "                eval_total_loss += eval_batch_loss\n",
    "        \n",
    "        # saving (checkpoint) the model every 2 epochs\n",
    "        if (epoch + 1) % 2 == 0:\n",
    "            translator.save_model()\n",
    "            \n",
    "        bleu, translated, inp_sent = translator.evaluate(\"The cat is adorable.\", \"這隻貓很可愛。\")\n",
    "        tn.set_postfix(loss=total_loss / len(train_loader), bleu=bleu)\n",
    "\n",
    "        print('    [Source]:', inp_sent)\n",
    "        print('[Translated]:', translated)\n",
    "        print(f\"training loss: {total_loss}\")\n",
    "        print(f\"validation loss: {eval_total_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "5e933e1e91ca4d8f9643760244d22d0e",
      "5fb6cd0426dd42a5b77cd53fd77933ba",
      "6e60970567af47cca7b51a339f87e464",
      "567b4896110b40e6885086b3b8d6116e",
      "f8d63166c90645ef85d1eb443f69dd87",
      "cbb5ce0155e0457fafab2eecf93eaa8a",
      "806e89807f4c41f0b46af6f97d19bce3",
      "f7e35a653ff54e7597429a5382fca263",
      "0ef0ddbe90b84a9e88ece84134eeff9a",
      "c6b6916d25b54f00bad3ce7c29085238",
      "755b12c268ee4072899c409347dd0fe1",
      "ec7dfe10185b44de8b42531eddd8a097",
      "e07db13d912442878d9c8eab33b77216",
      "468eb6fc7f7742099f70723952557d80",
      "7506071b90fb4aa1a74ccee77debadf7",
      "a41e66fa1f834efdb37c7400170649a9",
      "222135c9ba544b04b2a07a16915faa87",
      "c3e20bd067954be7a7597b01b02a2a28",
      "74766d930fda426192a1c09064486e1c",
      "7166f7c1c41948ddbb2cad9075bcde65",
      "56060bb1258c40cfbed834d5e5bf8751",
      "38e98de458624f42aa63607144f99e85",
      "343527623f3742fdba0a422d02f6d9e9",
      "3a9eb8d22e3e41378a85ed33c686a09f",
      "f75e07b9a32b4cb68b4a5a0266f4866d",
      "9e27b06aa582430e9199b6272b109e96",
      "273b88b2e87043b795c0fbcd49a5a768",
      "82a2ae43867a429eaeb14ff023b5d503",
      "dabd494b59a8404480fad988e0cd8dba",
      "75c8fe7fc1b14cc0980f660e98e815e0",
      "0e13ff5d873443c5bdd27f856388b5b8",
      "142792252dbe41a38fde27f262f96a54",
      "33a25b229d36440b9f69a0023565e328",
      "7f9d799de1b34ed1b32eb69692400989",
      "d99e913e71754bb5ac51f4d63112991b",
      "9b6bebb553ce4572ae3d7da2c7b341b0",
      "f7b7b8a416304ccf9a7f7f169b1532e4",
      "d3390a22be3c4099b2689c2c77893302",
      "9202851e2b1b4b6390ba5f6aaaeccc12",
      "242136dcfc2d4a7ea4c87128b91df389",
      "d7cc9eac31314876b0091067c3ffc3c7",
      "09c69ca35ae44b7fa6ee0adb553c242a",
      "043bf6225a9b4879921f4619e1006fbe",
      "4a5f3c27e3964b34a60d9d7ca10d8266",
      "b88244c314884cb0a88b2b9e30b3b7f7",
      "5d758d803be2437bbc783af30f314f45",
      "56d76acbc1ea42f29f027d2bc066c3a2",
      "e970daa296264f98863c6d41fc29cfec",
      "615354d52c584a04a4e0db847910526d",
      "73acc80b10c7472a929a4ba3200683f9",
      "45319a576c244edf8128e412256c294e",
      "c48212826bc84982a9095d438b74a7f6",
      "f88ebfde767a48fd9c54cca2c91ba403",
      "9572aa86a8d44a55b1202a40c50db6a9",
      "387555b2d7984279b5fb8f7ecd87f08b",
      "d803c7d9aa2047a6b6ba9130d488e9e9",
      "cf654e0ec5434544bc76eb3eb6d3d38f",
      "d794b459ef5048aeb23128b07a8f1f27",
      "0134ad2eed5649b3a6a69eac695e1f91",
      "f38d0cebe30c40a2b49fc9d8c613e80e",
      "f0bbcb34e8d8459ca85ef9e913c61885",
      "ef30a77e1c564e7197810017a52161e9",
      "1e953bd20fed49cb89f6d0950ab271d6",
      "fa433461ae9546a8a7b364770241a044",
      "7ab1c7ef700849d7bf85dba56ca15f48",
      "40be6ab0ae834301b8f987c531fc6786",
      "45de0eaa16c740edacaf815d1bd45ad8",
      "68ecaa02dcae475d94622f5689d43b35",
      "79301dcfc40f45b9b3544e2083afac3a",
      "dffd711c30624cfdb3deeaac0044b8be",
      "b49ba333fec04b74a7d58afe6527cfc8",
      "70c432057fa444f6a05a5c309b8e16ad",
      "bc1858f676f0477f9cb473c9cdb9b4dc",
      "229200754f434ebab4fe532797ab994a",
      "7ce70d1cc3514967842c2182eacaef38",
      "208ce28d339542c2911d30f0f8ba7b30",
      "87e828c2f952482c95098d8b372e3267",
      "d57760a9d31947ea804c6541002b69ee",
      "11227dc7706a4d4eb3d56e6b24046230",
      "e2b8142e810141cb98f32dd69816caf8",
      "bff58f06b48a422daa54797c7b0bae8e",
      "493b582d61f747b3b1cd401d95873947",
      "8fb009a0ae8347ae8f2642c22659d798",
      "6c2c153a47b44da98a7b2d4ea21f2bcd",
      "ac1a4108cfe14d3db6d8a4d49159738e",
      "1710447adf734328bc8e02e444acd634",
      "d42485810fc84ab89e4fa4978039e969",
      "c9fd99d9cb9542af972715438b50a6b8",
      "f5ba029ee4af4287b00e0417281d5468",
      "d50bd80c46444bf6819c2fa7c6f23b89",
      "b26fa4aaa6a644888ae77f80f3f0dd3d",
      "b7427cad2a854604b25f50f430bde685",
      "f50b1caceeb54b6ab6c9b890bacf1b6e",
      "fc712aa0370643ad9afbd283288f917a",
      "92ed7bd03109443887130acc6576ea17",
      "f44ac11eae1b47aca3d19c5739854b1c",
      "edfb391efee04b4a89b7118d682a428c",
      "0a1e69d4084a45b7adf5b7bfd5b0fc9a",
      "52b14a0cfd6c4a678e2cc5b3963942e2",
      "10c3a2684a014312bfd5452a1e7abffc",
      "df79ccdd4b9e489a9aadbcf3c49ca2c2",
      "a6392635b6b847988df2c478ab8a0996",
      "a62b859d7474452383e3352e649d4712",
      "16661bb89c524195a6406e967264d5d5",
      "5d24264799404b19baadd65f372c9a8e",
      "0989efd1d3ce4f16ae3380df147f17b2",
      "9ee49ac6cb0342c8b5f04a624d17c607",
      "f1fd4eb356124ab9b7efae5dcb0b4159",
      "b70e636e614a4d5fbeabab71eadeb444",
      "4531a0264ca54ad2a20d84eb087f9085",
      "1dad916f3dfa47dfa911a11b92764f3e",
      "2e81369ad1f74744bf8ac4a8080d2243",
      "7c6f9ddb322d4e8c94f778da007cde7b",
      "ba1dbcf939e94cc8b81047b2f74c4fb3",
      "479455b5dcfc4d729fcbfbc9a6fb7485",
      "e8d5c90480974a129cd92fd229a745fe",
      "174f883c374347c0951ffd27b197b810",
      "ef7f1f09d7b94bb38f604ce33be18cb4",
      "9703d8b86e334174bd5362fe5ebf8da0",
      "ecf4575c6eaa412f840c7de138517ee7",
      "83917775925645adbfacc6342d39f560",
      "5b97d936f17946c69d28b8e97d9d5f40",
      "ccd3eabbea25437e894fbaf5c8210484",
      "1f719390a44f4befbca65a456c9a769e",
      "bf7c22d19eac44e7b886663551cc3da7",
      "ecce16d736fe4d049da4c3f9dc2d2c72",
      "5ff691f8e09f4af8bb29e5cb73970791",
      "d04d672ba0604105b859db743842ca25",
      "6ebe47cc604b472f9f84c58d3902bdc8",
      "e672fb335774410f8073b807bf130670",
      "1e4c012acb8746e1953088601d456f1b",
      "ad69c4b779aa4411984a909001b3fb01",
      "6279401f534343f1924ee698185aaa9b",
      "a579353ab82c4614a8ae3ce380a1ddeb",
      "b1bde6c628464e10b24aacf2a24cd50f",
      "f404b3bc37c04c5ebe6478050ccfcc67",
      "9266ceed24764ac7ab3e0d7d77c536b0",
      "fbfbf3b931724602ad9e873256d0d8cd",
      "d41eb0aba78a4c6997230ff8b86ce4a4",
      "22501fec0b784d97b28ddfa0c2954f2e",
      "ed948db689b04c6c802ef2d7fc95d635",
      "21084dca8b0d438f95aaf0fafb06bc21",
      "cdcf0012e5e649f7bfb69cd43eafe8b3",
      "b024106226df40b98f74aca40a9da610",
      "4328d3cb67d842508ec7bed97ca499fa",
      "5184b158ab564f9988e1a115bfaa352f",
      "d420e3433064477a830fcaeefbead810",
      "88e182da27094ea590d0b88a0d8c2730",
      "2e9e47018eed4fde88ec68defb0aa5f3",
      "7685452a05554b43abc44222810d9c5d",
      "db3c6e01113a43d7a1b87bd890170112",
      "29180692f7c34108a39345a2af1e2f49",
      "ee020f9828ea42b4b42591b6dd791dee",
      "dfa76a40e80d4170a048d32c80b0f4f2",
      "e6229c58549e4b149600c898e65eb977",
      "9b6c2293d5b742acb354a25e6926b2ce",
      "5758aa09e3db4eea9e3b90c28378a0a1",
      "3e5f98aaa3c04a53bc73b0ae9deb4a56",
      "e67e1e863884454fb22dccb38146e05b",
      "4a15cd7dcf064fe090c6fa6c8c77d783",
      "46ad797f280a4f72b87d7d70e3890749",
      "f571c293a5a14dbba6d76896ae4abd46",
      "c066a2d72ccb4639affaa1c7edf4a6bc",
      "56c0b01d8d584e8d9fa14803ddea56f3",
      "34c60f7134c34873a3346320d762d1d9",
      "30bf0a75cdbf4fcfae4c362763fc9596",
      "4a3986abefcb4f4a9c283a3034da2e63",
      "4eb99f17821b48d7a397eb23b8a84a02",
      "2c2fddc6bff1407aaf039cd1ab41178e",
      "82c296cb8a9546189e5621a60aaad7ca",
      "0dc1a70eb11c4a90a42811c2c682d42e",
      "4ccfcaf2ff424a0d9f7551f8b17959c8",
      "c036855043d440f9be317c04f3bc2fc7",
      "176ad19f4d294cb9b2be417dca903ab9",
      "2de8f56ddea44942b029337e7ea663e3",
      "5b018e03a8084db088dc5d08ed141bda",
      "b53079f447f24e7ea7f2a52e1f018f22",
      "7646a3dcd5a6483f849065d2a5942879",
      "38cb5808005840f39ac19b98bae8ad05",
      "f901c309bf6f465bb5634c14367ae1f2",
      "e34e7a136b604ef6bfffbf5494c6bcf5",
      "2e62528c9494473dbdc262efa0fd9a31",
      "5d1238169a3342d681d8924d77a889f1",
      "f3a19404bfe7427691ae0627cbd97697",
      "15419a5f977f4f80877ff6c2d53ba8f2",
      "9efa067471004848a1c3f7643a7d7f2c",
      "5fa2d7981ec34a379de882f89dd5c282",
      "b07660a62ede4e299eef9bba12257133",
      "45f6947e16ab4a9fbc03e754ab4772ab",
      "56f5b9b467d14fc4a56bcc1002fd3dd4",
      "87fa0812b856411cae2e5de34c500f22",
      "dd3f6e18d61f42bb872c469a876f6a5b",
      "e57817b51a37468ab730c69d26dad283",
      "a5e3f96a81c341e8baa4a0d0c45aadb2",
      "79c1cc8cee534c6cbccaa45e4742f492",
      "7907cb4952714267a545022683f8261b",
      "5f23952a4df248188c31c1ca36533d55",
      "4a3c542ed4254bf497965898693810de",
      "8b7e4cc262f74d7ea5f35053ad59d5ed",
      "7d998cbd6a7644ad87c7dd0084f4ceff",
      "bd0819ec6b3f408cb1e2dcead13baa4b",
      "7629451f26a847ee84f6f9f6496b7c73",
      "ace8b2e97da3418c9694ec69988c26b9",
      "6136e6f325ea4cc9a8c89645f437328d",
      "32302862551b4a54ae77ef7eff7853ac",
      "1a15a218ce854d2e8b7d78c9c1d7d8cb",
      "a0294ea855cd4aa19734f01be14a5f5f",
      "226292d90baa4c219165d38f7ce843ff",
      "f02f468c86644918904bdb27b3b444ca",
      "3e02c7c4c049436789b5647f286519ce",
      "d524fa7e5e3c439d9b89e6e18575f659",
      "b97f9e2808864eb2aef3d63b02466a24",
      "21b6f3a3d5904a46b1a6f18f59770074",
      "e44f0accdb0f43a3aa5cf371508e5cfb",
      "c74256fe91ef4fd087c769d1937ae778",
      "f9047e3258a1449ca44bb8e205bdc907",
      "c0e944a974204cb98d6194f4ff0d595a",
      "86e3cc971d3e4e11aebbaa14c099ae3a",
      "bc8b90cb330b42078ee229f386666231",
      "dabdccbff9ed4839aa4a4d3a40d6df3c",
      "2704e71019ff425a867ee7982a171fa2",
      "625d459e2d784fbf806cdcd012536946",
      "d053e0c6bc2a4d0f852cccb9021617b0",
      "16d3a377d6024aa6b37ed693c1adbf05",
      "26178f19fe8f4a1a8b93a3ddce687743",
      "8b842ffb78594ba48793043afc07c83a",
      "4481d7c0467c45b0a5762cefc8d3962d",
      "0fc9f89a6f6f4f1ba18b93ca28afded1",
      "adf437a82cf548f6bd2f33480f2f6a2e",
      "de23eb4a650b40c2bcd4f911c250b198",
      "cfcdfe9346d3475dac11a9454adad2de",
      "eaae6d8209d2483b8e1a934377fd7602",
      "595f3f56c08a45d4bc7225f6aba233bd",
      "6a2614ee0fd64e28940bdeb125cc0595",
      "82fc620d0e1a45928f35a87e37a685ed",
      "0da894b056ca4e989a78a95fc2fdd07a",
      "d5f5d53521dc4906ae38e16c29ffc17d",
      "22b6cf9ab81947a59fa3f18b1e39c3c1",
      "cffc4311895f451488681d1fb1aff293",
      "ee930d0598024f608b91ea9c3c9920e3",
      "86fae665a6374ae6adec8422b652a3c7",
      "db45b2b9941c470e8669a0afb25f4015",
      "1c444c2ca5c24d5eb08d5dc99758e55a",
      "d068aed47c344a5b886cd5a0d931d60f",
      "3aeae882a8a3404bbb2c67ee93a65bd0",
      "aff501661b534fcb98709741e4203032",
      "050070428ce44359a36ea7b102c2c268",
      "6bf5ed43117c43f5be76612254dd8cc3",
      "1f83db3673b84cc78c1651aa68d5e5be",
      "5a60feaaa9c5442cbe379dcc679c7445",
      "b0e2ef5ebcfe424cbb3a008e86bef86c",
      "a94913b13c654956a4b0d5e2367342a9",
      "3184e2632687488e9e11f2700da511b7",
      "251c17f80e7e4335ae440d4dd071c69b",
      "2ed9864e29064282a13e4d8c9a02551f",
      "3e22abccdf2a4063ab73c6c8c80b2cfb",
      "2ea890caadac4344ae61c7222b677c8b",
      "8be04d70a900437e870f87ed2500e223",
      "2feb6179ba634732bbe1f9562ec910a3",
      "a42334c7e6964783b2c8121b4193f93f",
      "7c489bce3a684089b423d3b3cc77154a",
      "ac0c45779e9b4852b4035539a167ebd6",
      "6f9aa46aaf9c42918313f5050a1ff669",
      "ee8bac59f9a34f75b65ee384d19c3054",
      "294b53be68ca449f9c7040f6477ea6cf",
      "dd9a271344a74fd38d28d97510d3622c",
      "1c3b3a49d74542d9954f4facafd6583b",
      "b9d16ddb775145c4948826a934b5dc53",
      "b369dfb45ddc4605a975a00787ab0edc",
      "f5a4dc359047446eb55f7c50832efb51",
      "197961ddf2c042159d31094d190208a2",
      "41057bf7b6d842ee95affcf4231a5d32",
      "8dbc66eb726d47e9bc5db5c5d5595e2c",
      "128c95d982324e02acdb7ea829c14022",
      "cc1450480d274341af79f702537aeabd",
      "1eca2fd1ef6d43d385948b706dea17e0",
      "77609463008643febfc490ce2276bee4",
      "b475b5759a30470794a351e7987fabb0",
      "8f0d3da0fc9f4f76bafe5a19582e792e",
      "ae8723a870fb4585a90a73154db9edc0",
      "6aae78e47b2d4e3b948b8e16dd9c4fa8",
      "dfc9a3f25db24f90991ddea5adb7843a",
      "066ea8fcf2d948308f01c4eea911633c",
      "91fbb27ff54842bf8def50a27db85238",
      "3bfdfda807fc420190fb9c4b2dd2bcab",
      "613a665db9cb40948e4ee129150fa196",
      "7035242089934409bac943ae47d504d5",
      "ba718863f26e4513866e48ec30229e81",
      "a152c0e830714a7388273863b9b70569",
      "0a80fd4a01dc478bbe169093ae7a6e6b",
      "f42b36bb2777462a9ff0ed2a3cd02d1c",
      "96c5b7f305ab4f518a008b176add15ee",
      "d5fb9e9b2eb14804ac04c20bb9121d2a",
      "b491cf2a4a9a4c31bf90325c4799ca38",
      "3d6b74ffd4f24e7da1cebef88328e62a",
      "dc28f51bfdb04aec8303298ad30f066f",
      "75bcace64fe148408f1f49c34ec106fb",
      "6b6ddb5f874546a984b4a704eb1452bd",
      "169f501249e946a297f845fb7a9a5e76",
      "ff309cea55bd4409bb4b32043278c3b1",
      "a1ac13a1ffbc4c439c472279d5c2fdb5",
      "8db4246b21ca4f5d851ae04b96674a76",
      "18cb0a564f6a414fbf59d211136acba6",
      "13600a9cf5e34a53aa0572bafed12415",
      "d39f497a2d864c188755386f516809a1",
      "b657c22f3d664c65a4f8faf6dc86591a",
      "525e1e1801e94d93b44470c1e386e14d",
      "56d91764b0ad4e6ba9192a7b67f8277c",
      "d1493148ea5d429caff82c2bfc0de286",
      "a11e0c1080f448d182523d419969dc6f",
      "c15c435bc16847ab815268274f1644f1",
      "03544dcd9fad4d06a07e59988588e972",
      "abf2588864164b38afe80877aa405663",
      "9cb1218e2df849dc97cb53e616808b64",
      "cec12dfd95924f9a98a38dd5f3cee313",
      "18c80a599a844674b778037c2775421a",
      "eedc5c84e25346a392c18f370f771499",
      "549afb2c2b944b72968ee3dede790f9b",
      "131a9176e09f43ed837376730042de91",
      "37c10c6b45044585ba9038afbc73cd34",
      "2597432fea424e6fa86469dd8146f58b",
      "8b7d520a480a4c9f9031a68b6654fd59",
      "3cd2130032394cea901da4bea483f43c",
      "e7e20aaa714e4042b2ac26328d6e5450",
      "2be0f2bb71f7435696e3bf005c3d5a90",
      "28280847ecbf4013b13f01ea8ae2cbec",
      "503cdece9c46463ca27ec9d7541257dc",
      "85c093ec91904f4e82e50f2dffcf90ed",
      "80e34d9c67ea48f5a1d3fafc144818ec",
      "db7b5fc3b806467fb6e399510f87678d"
     ]
    },
    "id": "2R5G_taoZ1DP",
    "outputId": "4e08d339-0a57-4643-d426-e09583c0882a"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "335e2dc38a764d5e9fcb8bdf01660afc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/462 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [Source]: <sos> the cat is adorable . <eos>\n",
      "[Translated]: <sos> 的 是 一 个 。 <eos>\n",
      "training loss: 1469.2644093414483\n",
      "validation loss: 847.7313242174887\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd6e688808c54ae291bcc930a7ab090c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/462 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [Source]: <sos> the cat is adorable . <eos>\n",
      "[Translated]: <sos> 所 有 的 。 <eos>\n",
      "training loss: 1052.0327899174679\n",
      "validation loss: 681.9518570208543\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88d62034f2c64839bd55d0a3697984d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/462 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [Source]: <sos> the cat is adorable . <eos>\n",
      "[Translated]: <sos> 所 有 的 。 <eos>\n",
      "training loss: 832.099831076115\n",
      "validation loss: 566.9420728311037\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e02633f38d284f0f8ccf0c0cc03666ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/462 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [Source]: <sos> the cat is adorable . <eos>\n",
      "[Translated]: <sos> 所 有 很 难 。 <eos>\n",
      "training loss: 675.6015781976794\n",
      "validation loss: 470.2029368660419\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fbf0a898e8941afa88073ed3b7f54bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/462 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [Source]: <sos> the cat is adorable . <eos>\n",
      "[Translated]: <sos> 白 。 <eos>\n",
      "training loss: 577.2662894820987\n",
      "validation loss: 372.1735665719375\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52d6abc313354645b52b35cc644b75c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/462 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [Source]: <sos> the cat is adorable . <eos>\n",
      "[Translated]: <sos> 白 地 方 都 很 冷 。 <eos>\n",
      "training loss: 465.84356672150915\n",
      "validation loss: 309.5830808631293\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fe33a8cb03b4eeebd861413f6437118",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/462 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [Source]: <sos> the cat is adorable . <eos>\n",
      "[Translated]: <sos> 很 冷 。 <eos>\n",
      "training loss: 390.6665150132846\n",
      "validation loss: 251.35051302831585\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48a5d61ee07c4396b7a4018c41e27b8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/462 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [Source]: <sos> the cat is adorable . <eos>\n",
      "[Translated]: <sos> 白 地 是 很 冷 。 <eos>\n",
      "training loss: 328.13168661913124\n",
      "validation loss: 229.67037013893122\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b2ab3b8c243465b843059ba0260c13f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/462 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [Source]: <sos> the cat is adorable . <eos>\n",
      "[Translated]: <sos> 很 冷 。 <eos>\n",
      "training loss: 275.10410647727764\n",
      "validation loss: 271.5710144274113\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9e3a9483af34e73a5d3fa0f30b77a35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/462 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [Source]: <sos> the cat is adorable . <eos>\n",
      "[Translated]: <sos> 所 有 人 很 可 能 。 <eos>\n",
      "training loss: 236.09665515390702\n",
      "validation loss: 168.2533051045884\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7747107338564841a2462cb2199bb092",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/462 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [Source]: <sos> the cat is adorable . <eos>\n",
      "[Translated]: <sos> 它 很 危 。 <eos>\n",
      "training loss: 187.3538822272524\n",
      "validation loss: 232.3167138932162\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72e8b99cbe554528aea48bd68e5083f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/462 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [Source]: <sos> the cat is adorable . <eos>\n",
      "[Translated]: <sos> 地 区 。 <eos>\n",
      "training loss: 220.48337440171264\n",
      "validation loss: 126.49653280028998\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "422470229b0145ad9c28c0bc87d7ea65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/462 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [Source]: <sos> the cat is adorable . <eos>\n",
      "[Translated]: <sos> 它 很 有 。 <eos>\n",
      "training loss: 142.38324241688264\n",
      "validation loss: 105.22019041332726\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fee7a95f7186400fbe253f21e7e71f5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/462 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [Source]: <sos> the cat is adorable . <eos>\n",
      "[Translated]: <sos> 它 很 可 愛 。 <eos>\n",
      "training loss: 110.10599879257703\n",
      "validation loss: 77.56605690994589\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bd60b7479664731979fe718ea2c09e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/462 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [Source]: <sos> the cat is adorable . <eos>\n",
      "[Translated]: <sos> 船 是 很 危 。 <eos>\n",
      "training loss: 89.67628832579696\n",
      "validation loss: 77.25971273034158\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b8cf93073c14b939eada0d95028c11e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/462 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [Source]: <sos> the cat is adorable . <eos>\n",
      "[Translated]: <sos> 危 险 很 可 愛 。 <eos>\n",
      "training loss: 83.30999135849252\n",
      "validation loss: 125.45514113349469\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52290ada27db48229b0633bf2ac4b44d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/462 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [Source]: <sos> the cat is adorable . <eos>\n",
      "[Translated]: <sos> 它 很 可 愛 。 <eos>\n",
      "training loss: 83.52549726336886\n",
      "validation loss: 89.36690908992234\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aebd39c63311497db75d47332ed66de2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/462 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [Source]: <sos> the cat is adorable . <eos>\n",
      "[Translated]: <sos> 它 。 <eos>\n",
      "training loss: 76.45442207945234\n",
      "validation loss: 73.35781662263216\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0487fdd2964d49738a734aa79944e1b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/462 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [Source]: <sos> the cat is adorable . <eos>\n",
      "[Translated]: <sos> 危 险 很 危 。 <eos>\n",
      "training loss: 74.1542040872521\n",
      "validation loss: 97.8381220612057\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a37b387453943ccabf30cc6c5542359",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/462 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [Source]: <sos> the cat is adorable . <eos>\n",
      "[Translated]: <sos> 它 是 湖 。 <eos>\n",
      "training loss: 63.119350325262026\n",
      "validation loss: 80.80101161761098\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05e0667ecfa642c9a9f5e41e686f9a63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/462 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [Source]: <sos> the cat is adorable . <eos>\n",
      "[Translated]: <sos> 危 险 很 可 愛 。 <eos>\n",
      "training loss: 64.81796635697609\n",
      "validation loss: 57.89700406361006\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b6acdeb307a46ef985ae2f6456187ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/462 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [Source]: <sos> the cat is adorable . <eos>\n",
      "[Translated]: <sos> 。 <eos>\n",
      "training loss: 51.57286736164841\n",
      "validation loss: 51.6366244072228\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9a285ba74b94f27bf56e1182e1ff89b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/462 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [Source]: <sos> the cat is adorable . <eos>\n",
      "[Translated]: <sos> 它 是 黑 人 是 黑 。 <eos>\n",
      "training loss: 58.91404148526248\n",
      "validation loss: 72.8202497902855\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a08d6b4d06eb4aab8ab712b6051e284e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/462 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [Source]: <sos> the cat is adorable . <eos>\n",
      "[Translated]: <sos> 它 很 可 愛 。 <eos>\n",
      "training loss: 58.6116004933473\n",
      "validation loss: 48.101496989672235\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "629d766db114478286e21015c9feb1c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/462 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [Source]: <sos> the cat is adorable . <eos>\n",
      "[Translated]: <sos> 。 <eos>\n",
      "training loss: 58.53594063271745\n",
      "validation loss: 46.90209296519008\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f671564a426b4ddfbf34362cc6e83bca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/462 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [Source]: <sos> the cat is adorable . <eos>\n",
      "[Translated]: <sos> 它 很 可 愛 。 <eos>\n",
      "training loss: 43.66899895291139\n",
      "validation loss: 34.667820456273404\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd9790615b734f428047d783c4467c6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/462 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [Source]: <sos> the cat is adorable . <eos>\n",
      "[Translated]: <sos> 它 很 可 愛 。 <eos>\n",
      "training loss: 39.20054997221913\n",
      "validation loss: 36.6207997017852\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13419e20990e4f8792416f5752865bd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/462 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [Source]: <sos> the cat is adorable . <eos>\n",
      "[Translated]: <sos> 。 <eos>\n",
      "training loss: 38.763050352992565\n",
      "validation loss: 41.26712187958673\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f92878d6851448d4ba274444bcc1271a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/462 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [Source]: <sos> the cat is adorable . <eos>\n",
      "[Translated]: <sos> 。 <eos>\n",
      "training loss: 44.728595197940024\n",
      "validation loss: 60.21149675563772\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26b754ef8212401a922186b950dd8bd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/462 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [Source]: <sos> the cat is adorable . <eos>\n",
      "[Translated]: <sos> 。 <eos>\n",
      "training loss: 48.053712576023486\n",
      "validation loss: 59.606776980304765\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    config = {\n",
    "        'src_vocab_size': len(en_vocab),\n",
    "        'tar_vocab_size': len(zh_vocab),\n",
    "        'src_emb_dim': 256,\n",
    "        'tar_emb_dim': 256,\n",
    "        'enc_units': 512,\n",
    "        'dec_units': 512,\n",
    "        'att_units': 512,\n",
    "        'batch_size': 64,\n",
    "        'epochs': 30,\n",
    "        'learning_rate': 1e-3,\n",
    "        'checkpoint_dir': './checkpoints/',\n",
    "        'device': 'cuda:0',\n",
    "    }\n",
    "\n",
    "    # build translator model\n",
    "    translator = Translator(config, en_vocab, zh_vocab, loss_fn).to(config['device'])\n",
    "\n",
    "    # train model\n",
    "    train(translator, train_loader, valid_loader, config, use_teacher_forcing=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n250XbnjOaqP"
   },
   "source": [
    "## Restore the latest checkpoint and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EXBO26iwlGiB",
    "outputId": "12473224-11e3-4bcd-f794-6cfce6da2e3d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.6975624222192167e-155, '<sos> 。 <eos>', '<sos> the cat is adorable . <eos>')\n",
      "(3.4139826703418696e-78, '<sos> 狗 。 <eos>', '<sos> i have a dog . <eos>')\n",
      "(0.6434588841607617, '<sos> 在 下 雨 了 。 <eos>', '<sos> it is raining . <eos>')\n"
     ]
    }
   ],
   "source": [
    "translator.load_model()\n",
    "# input: English string to be translated, Chinese string reference\n",
    "# output: (bleu score, translated & tokenized Chinese string, tokenized English string)\n",
    "print(translator.evaluate(\"The cat is adorable.\", '這隻貓很可愛。'))\n",
    "print(translator.evaluate('I have a dog.', '我有一条狗。'))\n",
    "print(translator.evaluate(\"It is raining.\", '下雨了。'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "690V7WSmqFFa"
   },
   "source": [
    "## Applying OpenCC\n",
    "Adding a Traditional Chinese to Simplified Chinese conversion module allows us to use Traditional Chinese as the input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GM4MHIeIqXbt",
    "outputId": "9b155a3c-17dc-4899-b46e-2d5cb2aef5e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "出租车到了。\n",
      "(0.7506238537503395, '<sos> 到 出 租 车 到 了 。 <eos>', '<sos> the taxi has arrived . <eos>')\n"
     ]
    }
   ],
   "source": [
    "import opencc\n",
    "tw2sp = opencc.OpenCC('tw2sp.json').convert\n",
    "s2twp = opencc.OpenCC('s2twp.json').convert\n",
    "\n",
    "eng_s = \"The taxi has arrived.\"\n",
    "tw_ref = \"計程車到了。\"\n",
    "sp_ref = tw2sp(tw_ref)\n",
    "print(sp_ref)\n",
    "\n",
    "print(translator.evaluate(eng_s, sp_ref))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
